{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87d1578c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "from collections import OrderedDict \n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import paddle\n",
    "from paddle.nn import Embedding\n",
    "import paddle.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f05402",
   "metadata": {},
   "source": [
    "使用text8数据集，该数据集里包含了大量从维基百科收集到的英文语料，下载后的文件被保存在当前目录的“text8.txt”文件内"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c26cfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载语料用来训练word2vec\n",
    "def download():\n",
    "    # 可以从百度云服务器下载一些开源数据集（dataset.bj.bcebos.com）\n",
    "    corpus_url = \"https://dataset.bj.bcebos.com/word2vec/text8.txt\"\n",
    "    # 使用python的requests包下载数据集到本地\n",
    "    web_request = requests.get(corpus_url)\n",
    "    corpus = web_request.content\n",
    "    # 把下载后的文件存储在当前目录的text8.txt文件内\n",
    "    with open(\"./text8.txt\", \"wb\") as f:\n",
    "        f.write(corpus)\n",
    "    f.close()\n",
    "download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0633e8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " anarchism originated as a term of abuse first used against early working class radicals including the diggers of the english revolution and the sans culottes of the french revolution whilst the term is still used in a pejorative way to describe any act that used violent means to destroy the organization of society it has also been taken up as a positive label by self defined anarchists the word anarchism is derived from the greek without archons ruler chief king anarchism as a political philoso\n"
     ]
    }
   ],
   "source": [
    "# 读取text8数据\n",
    "def load_text8():\n",
    "    with open(\"./text8.txt\", \"r\") as f:\n",
    "        corpus = f.read().strip(\"\\n\")\n",
    "    f.close()\n",
    "\n",
    "    return corpus\n",
    "\n",
    "corpus = load_text8()\n",
    "\n",
    "# 打印前500个字符，简要看一下这个语料的样子\n",
    "print(corpus[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75a4804",
   "metadata": {},
   "source": [
    "在自然语言处理中，需要先对语料进行切词。对于英文来说，可以比较简单地直接使用空格进行切词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b067e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against', 'early', 'working', 'class', 'radicals', 'including', 'the', 'diggers', 'of', 'the', 'english', 'revolution', 'and', 'the', 'sans', 'culottes', 'of', 'the', 'french', 'revolution', 'whilst', 'the', 'term', 'is', 'still', 'used', 'in', 'a', 'pejorative', 'way', 'to', 'describe', 'any', 'act', 'that', 'used', 'violent', 'means', 'to', 'destroy', 'the']\n"
     ]
    }
   ],
   "source": [
    "# 对语料进行预处理（分词）\n",
    "def data_preprocess(corpus):\n",
    "    # 由于英文单词出现在句首的时候经常要大写，所以我们把所有英文字符都转换为小写，\n",
    "    # 以便对语料进行归一化处理（Apple vs apple等）\n",
    "    corpus = corpus.strip().lower()\n",
    "    corpus = corpus.split(\" \")\n",
    "    return corpus\n",
    "\n",
    "corpus = data_preprocess(corpus)\n",
    "print(corpus[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f6ad30",
   "metadata": {},
   "source": [
    "在经过切词后，需要对语料进行统计，为每个词构造ID。一般来说，可以根据每个词在语料中出现的频次构造ID，频次越高，ID越小，便于对词典进行管理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1320cbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are totoally 253854 different words in the corpus\n",
      "word the, its id 0, its word freq 1061396\n",
      "word of, its id 1, its word freq 593677\n",
      "word and, its id 2, its word freq 416629\n",
      "word one, its id 3, its word freq 411764\n",
      "word in, its id 4, its word freq 372201\n",
      "word a, its id 5, its word freq 325873\n",
      "word to, its id 6, its word freq 316376\n",
      "word zero, its id 7, its word freq 264975\n",
      "word nine, its id 8, its word freq 250430\n",
      "word two, its id 9, its word freq 192644\n",
      "word is, its id 10, its word freq 183153\n",
      "word as, its id 11, its word freq 131815\n",
      "word eight, its id 12, its word freq 125285\n",
      "word for, its id 13, its word freq 118445\n",
      "word s, its id 14, its word freq 116710\n",
      "word five, its id 15, its word freq 115789\n",
      "word three, its id 16, its word freq 114775\n",
      "word was, its id 17, its word freq 112807\n",
      "word by, its id 18, its word freq 111831\n",
      "word that, its id 19, its word freq 109510\n",
      "word four, its id 20, its word freq 108182\n",
      "word six, its id 21, its word freq 102145\n",
      "word seven, its id 22, its word freq 99683\n",
      "word with, its id 23, its word freq 95603\n",
      "word on, its id 24, its word freq 91250\n",
      "word are, its id 25, its word freq 76527\n",
      "word it, its id 26, its word freq 73334\n",
      "word from, its id 27, its word freq 72871\n",
      "word or, its id 28, its word freq 68945\n",
      "word his, its id 29, its word freq 62603\n",
      "word an, its id 30, its word freq 61925\n",
      "word be, its id 31, its word freq 61281\n",
      "word this, its id 32, its word freq 58832\n",
      "word which, its id 33, its word freq 54788\n",
      "word at, its id 34, its word freq 54576\n",
      "word he, its id 35, its word freq 53573\n",
      "word also, its id 36, its word freq 44358\n",
      "word not, its id 37, its word freq 44033\n",
      "word have, its id 38, its word freq 39712\n",
      "word were, its id 39, its word freq 39086\n",
      "word has, its id 40, its word freq 37866\n",
      "word but, its id 41, its word freq 35358\n",
      "word other, its id 42, its word freq 32433\n",
      "word their, its id 43, its word freq 31523\n",
      "word its, its id 44, its word freq 29567\n",
      "word first, its id 45, its word freq 28810\n",
      "word they, its id 46, its word freq 28553\n",
      "word some, its id 47, its word freq 28161\n",
      "word had, its id 48, its word freq 28100\n",
      "word all, its id 49, its word freq 26229\n"
     ]
    }
   ],
   "source": [
    "# 构造词典，统计每个词的频率，并根据频率将每个词转换为一个整数id\n",
    "def build_dict(corpus):\n",
    "    # 首先统计每个不同词的频率（出现的次数），使用一个词典记录\n",
    "    word_freq_dict = dict()\n",
    "    for word in corpus:\n",
    "        if word not in word_freq_dict:\n",
    "            word_freq_dict[word] = 0\n",
    "        word_freq_dict[word] += 1\n",
    "\n",
    "    # 将这个词典中的词，按照出现次数排序，出现次数越高，排序越靠前\n",
    "    word_freq_dict = sorted(word_freq_dict.items(), key = lambda x:x[1], reverse = True)\n",
    "    \n",
    "    # 构造3个不同的词典，分别存储：\n",
    "    # 每个词到id的映射关系：word2id_dict\n",
    "    # 每个id出现的频率：word2id_freq\n",
    "    # 每个id到词的映射关系：id2word_dict\n",
    "    word2id_dict = dict()\n",
    "    word2id_freq = dict()\n",
    "    id2word_dict = dict()\n",
    "\n",
    "    # 按照频率，从高到低，开始遍历每个单词，并为这个单词构造一个独一无二的id\n",
    "    for word, freq in word_freq_dict:\n",
    "        curr_id = len(word2id_dict)\n",
    "        word2id_dict[word] = curr_id\n",
    "        word2id_freq[word2id_dict[word]] = freq\n",
    "        id2word_dict[curr_id] = word\n",
    "\n",
    "    return word2id_freq, word2id_dict, id2word_dict\n",
    "\n",
    "word2id_freq, word2id_dict, id2word_dict = build_dict(corpus)\n",
    "vocab_size = len(word2id_freq)\n",
    "print(\"there are totoally %d different words in the corpus\" % vocab_size)\n",
    "for _, (word, word_id) in zip(range(50), word2id_dict.items()):\n",
    "    print(\"word %s, its id %d, its word freq %d\" % (word, word_id, word2id_freq[word_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb906a0",
   "metadata": {},
   "source": [
    "得到word2id词典后，还需要进一步处理原始语料，把每个词替换成对应的ID，便于神经网络进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c291b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17005207 tokens in the corpus\n",
      "[5233, 3080, 11, 5, 194, 1, 3133, 45, 58, 155, 127, 741, 476, 10571, 133, 0, 27349, 1, 0, 102, 854, 2, 0, 15067, 58112, 1, 0, 150, 854, 3580, 0, 194, 10, 190, 58, 4, 5, 10712, 214, 6, 1324, 104, 454, 19, 58, 2731, 362, 6, 3672, 0]\n"
     ]
    }
   ],
   "source": [
    "# 把语料转换为id序列\n",
    "def convert_corpus_to_id(corpus, word2id_dict):\n",
    "    # 使用一个循环，将语料中的每个词替换成对应的id，以便于神经网络进行处理\n",
    "    corpus = [word2id_dict[word] for word in corpus]\n",
    "    return corpus\n",
    "\n",
    "corpus = convert_corpus_to_id(corpus, word2id_dict)\n",
    "print(\"%d tokens in the corpus\" % len(corpus))\n",
    "print(corpus[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7fb684",
   "metadata": {},
   "source": [
    "需要使用二次采样法处理原始文本。二次采样法的主要思想是降低高频词在语料中出现的频次。方法是随机将高频的词抛弃，频率越高，被抛弃的概率就越大；频率越低，被抛弃的概率就越小。标点符号或冠词这样的高频词就会被抛弃，从而优化整个词表的词向量训练效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24139390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8742418 tokens in the corpus\n",
      "[5233, 3080, 194, 3133, 58, 155, 741, 10571, 27349, 854, 15067, 58112, 150, 854, 3580, 190, 10712, 214, 1324, 454, 19, 2731, 3672, 36, 53, 11, 1423, 2757, 567, 7088, 5233, 1052, 320, 248, 44611, 2877, 792, 5233, 200, 602, 1134, 2621, 25, 8983, 279, 4147, 6437, 4186, 5233, 1137]\n"
     ]
    }
   ],
   "source": [
    "# 使用二次采样算法（subsampling）处理语料，强化训练效果\n",
    "def subsampling(corpus, word2id_freq):\n",
    "    \n",
    "    # 这个discard函数决定了一个词会不会被替换，这个函数是具有随机性的，每次调用结果不同\n",
    "    # 如果一个词的频率很大，那么它被遗弃的概率就很大\n",
    "    def discard(word_id):\n",
    "        return random.uniform(0, 1) < 1 - math.sqrt(1e-4 / word2id_freq[word_id] * len(corpus))\n",
    "\n",
    "    corpus = [word for word in corpus if not discard(word)]\n",
    "    return corpus\n",
    "\n",
    "corpus = subsampling(corpus, word2id_freq)\n",
    "print(\"%d tokens in the corpus\" % len(corpus))\n",
    "print(corpus[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4179da",
   "metadata": {},
   "source": [
    "在完成语料数据预处理之后，需要构造训练数据。根据上面的描述，我们需要使用一个滑动窗口对语料从左到右扫描，在每个窗口内，中心词需要预测它的上下文，并形成训练数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e841a2e3",
   "metadata": {},
   "source": [
    "在实际操作中，由于词表往往很大（50000，100000等），对大词表的一些矩阵运算（如softmax）需要消耗巨大的资源，因此可以通过负采样的方式模拟softmax的结果。\n",
    "\n",
    "给定一个中心词和一个需要预测的上下文词，把这个上下文词作为正样本。\n",
    "通过词表随机采样的方式，选择若干个负样本。\n",
    "把一个大规模分类问题转化为一个2分类问题，通过这种方式优化计算速度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "097898f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "center_word anarchism, target originated, label 1\n",
      "center_word anarchism, target desensitisation, label 0\n",
      "center_word anarchism, target longenecker, label 0\n",
      "center_word anarchism, target jigten, label 0\n",
      "center_word anarchism, target reichsparteitag, label 0\n",
      "center_word anarchism, target term, label 1\n",
      "center_word anarchism, target mroon, label 0\n",
      "center_word anarchism, target playful, label 0\n",
      "center_word anarchism, target jojen, label 0\n",
      "center_word anarchism, target risner, label 0\n",
      "center_word originated, target anarchism, label 1\n",
      "center_word originated, target fruit, label 0\n",
      "center_word originated, target huvadu, label 0\n",
      "center_word originated, target tiden, label 0\n",
      "center_word originated, target vampires, label 0\n",
      "center_word originated, target term, label 1\n",
      "center_word originated, target lithgow, label 0\n",
      "center_word originated, target conmebol, label 0\n",
      "center_word originated, target soundtracknet, label 0\n",
      "center_word originated, target weberian, label 0\n",
      "center_word originated, target abuse, label 1\n",
      "center_word originated, target daffy, label 0\n",
      "center_word originated, target callimachus, label 0\n",
      "center_word originated, target warms, label 0\n",
      "center_word originated, target anthracite, label 0\n",
      "center_word term, target anarchism, label 1\n",
      "center_word term, target marginally, label 0\n",
      "center_word term, target smoothbore, label 0\n",
      "center_word term, target mangano, label 0\n",
      "center_word term, target laths, label 0\n",
      "center_word term, target originated, label 1\n",
      "center_word term, target brunning, label 0\n",
      "center_word term, target iodination, label 0\n",
      "center_word term, target intelligenceespionagemanagement, label 0\n",
      "center_word term, target sanada, label 0\n",
      "center_word term, target abuse, label 1\n",
      "center_word term, target seeds, label 0\n",
      "center_word term, target konerko, label 0\n",
      "center_word term, target phillis, label 0\n",
      "center_word term, target vartan, label 0\n",
      "center_word term, target used, label 1\n",
      "center_word term, target huysum, label 0\n",
      "center_word term, target swearin, label 0\n",
      "center_word term, target gershowitzs, label 0\n",
      "center_word term, target akedah, label 0\n",
      "center_word abuse, target term, label 1\n",
      "center_word abuse, target qinghong, label 0\n",
      "center_word abuse, target ported, label 0\n",
      "center_word abuse, target tondern, label 0\n",
      "center_word abuse, target marching, label 0\n"
     ]
    }
   ],
   "source": [
    "# 构造数据，准备模型训练\n",
    "# max_window_size代表了最大的window_size的大小，程序会根据max_window_size从左到右扫描整个语料\n",
    "# negative_sample_num代表了对于每个正样本，我们需要随机采样多少负样本用于训练，\n",
    "# 一般来说，negative_sample_num的值越大，训练效果越稳定，但是训练速度越慢。 \n",
    "def build_data(corpus, word2id_dict, word2id_freq, max_window_size = 3, negative_sample_num = 4):\n",
    "    \n",
    "    # 使用一个list存储处理好的数据\n",
    "    dataset = []\n",
    "\n",
    "    # 从左到右，开始枚举每个中心点的位置\n",
    "    for center_word_idx in range(len(corpus)):\n",
    "        # 以max_window_size为上限，随机采样一个window_size，这样会使得训练更加稳定\n",
    "        window_size = random.randint(1, max_window_size)\n",
    "        # 当前的中心词就是center_word_idx所指向的词\n",
    "        center_word = corpus[center_word_idx]\n",
    "\n",
    "        # 以当前中心词为中心，左右两侧在window_size内的词都可以看成是正样本\n",
    "        positive_word_range = (max(0, center_word_idx - window_size), min(len(corpus) - 1, center_word_idx + window_size))\n",
    "        positive_word_candidates = [corpus[idx] for idx in range(positive_word_range[0], positive_word_range[1]+1) if idx != center_word_idx]\n",
    "\n",
    "        # 对于每个正样本来说，随机采样negative_sample_num个负样本，用于训练\n",
    "        for positive_word in positive_word_candidates:\n",
    "            # 首先把（中心词，正样本，label=1）的三元组数据放入dataset中，\n",
    "            # 这里label=1表示这个样本是个正样本\n",
    "            dataset.append((center_word, positive_word, 1))\n",
    "\n",
    "            # 开始负采样\n",
    "            i = 0\n",
    "            while i < negative_sample_num:\n",
    "                negative_word_candidate = random.randint(0, vocab_size-1)\n",
    "\n",
    "                if negative_word_candidate not in positive_word_candidates:\n",
    "                    # 把（中心词，正样本，label=0）的三元组数据放入dataset中，\n",
    "                    # 这里label=0表示这个样本是个负样本\n",
    "                    dataset.append((center_word, negative_word_candidate, 0))\n",
    "                    i += 1\n",
    "    return dataset\n",
    "corpus_light = corpus[:int(len(corpus)*0.2)]\n",
    "dataset = build_data(corpus_light, word2id_dict, word2id_freq)\n",
    "for _, (center_word, target_word, label) in zip(range(50), dataset):\n",
    "    print(\"center_word %s, target %s, label %d\" % (id2word_dict[center_word],id2word_dict[target_word], label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07174b95",
   "metadata": {},
   "source": [
    "训练数据准备好后，把训练数据都组装成mini-batch，并准备输入到网络中进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f4ae6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[  1074],\n",
      "       [140144],\n",
      "       [     0],\n",
      "       [   395],\n",
      "       [    90],\n",
      "       [  2614],\n",
      "       [ 14098],\n",
      "       [   403],\n",
      "       [  6691],\n",
      "       [     1],\n",
      "       [ 75607],\n",
      "       [  1808],\n",
      "       [   177],\n",
      "       [  8590],\n",
      "       [  1202],\n",
      "       [  1430],\n",
      "       [    19],\n",
      "       [    55],\n",
      "       [  3501],\n",
      "       [  2118],\n",
      "       [ 74820],\n",
      "       [  3948],\n",
      "       [   370],\n",
      "       [  3346],\n",
      "       [  1554],\n",
      "       [   368],\n",
      "       [  1446],\n",
      "       [   442],\n",
      "       [100673],\n",
      "       [    54],\n",
      "       [ 10877],\n",
      "       [    29],\n",
      "       [   253],\n",
      "       [ 16219],\n",
      "       [ 41514],\n",
      "       [  2222],\n",
      "       [  2823],\n",
      "       [     3],\n",
      "       [ 15782],\n",
      "       [  2036],\n",
      "       [ 58176],\n",
      "       [  1527],\n",
      "       [   960],\n",
      "       [  1581],\n",
      "       [    53],\n",
      "       [   154],\n",
      "       [     4],\n",
      "       [  3343],\n",
      "       [   742],\n",
      "       [  1470],\n",
      "       [  2389],\n",
      "       [   847],\n",
      "       [    49],\n",
      "       [   523],\n",
      "       [ 33818],\n",
      "       [  6503],\n",
      "       [ 13710],\n",
      "       [ 75986],\n",
      "       [105781],\n",
      "       [   325],\n",
      "       [  2286],\n",
      "       [ 21674],\n",
      "       [ 36075],\n",
      "       [    24],\n",
      "       [  8815],\n",
      "       [  9197],\n",
      "       [  3506],\n",
      "       [     3],\n",
      "       [ 66864],\n",
      "       [   625],\n",
      "       [  3441],\n",
      "       [  4221],\n",
      "       [     4],\n",
      "       [   611],\n",
      "       [  1499],\n",
      "       [   377],\n",
      "       [     0],\n",
      "       [  6374],\n",
      "       [   471],\n",
      "       [   798],\n",
      "       [  3242],\n",
      "       [  4554],\n",
      "       [ 54634],\n",
      "       [ 14812],\n",
      "       [  5674],\n",
      "       [  6288],\n",
      "       [   866],\n",
      "       [  1546],\n",
      "       [  1693],\n",
      "       [  1009],\n",
      "       [  4029],\n",
      "       [  2301],\n",
      "       [  3817],\n",
      "       [  3040],\n",
      "       [ 48512],\n",
      "       [   958],\n",
      "       [ 26910],\n",
      "       [   510],\n",
      "       [   358],\n",
      "       [   293],\n",
      "       [   127],\n",
      "       [   283],\n",
      "       [ 13947],\n",
      "       [  5074],\n",
      "       [ 11874],\n",
      "       [ 10987],\n",
      "       [  6945],\n",
      "       [    32],\n",
      "       [   330],\n",
      "       [  5106],\n",
      "       [ 45237],\n",
      "       [   356],\n",
      "       [  3843],\n",
      "       [  6821],\n",
      "       [ 38579],\n",
      "       [ 18249],\n",
      "       [  5197],\n",
      "       [   255],\n",
      "       [  2734],\n",
      "       [  8348],\n",
      "       [   721],\n",
      "       [   872],\n",
      "       [    47],\n",
      "       [   381],\n",
      "       [    67],\n",
      "       [   595],\n",
      "       [ 12077],\n",
      "       [    14]], dtype=int64), array([[152719],\n",
      "       [ 78313],\n",
      "       [  2814],\n",
      "       [ 18861],\n",
      "       [117704],\n",
      "       [ 46606],\n",
      "       [ 70720],\n",
      "       [ 35771],\n",
      "       [223827],\n",
      "       [ 67558],\n",
      "       [135061],\n",
      "       [ 20621],\n",
      "       [    30],\n",
      "       [187111],\n",
      "       [ 10474],\n",
      "       [252719],\n",
      "       [ 39738],\n",
      "       [244851],\n",
      "       [    42],\n",
      "       [ 94319],\n",
      "       [135119],\n",
      "       [   530],\n",
      "       [   478],\n",
      "       [197123],\n",
      "       [ 80686],\n",
      "       [  3232],\n",
      "       [ 27820],\n",
      "       [ 97204],\n",
      "       [100671],\n",
      "       [ 16806],\n",
      "       [ 76475],\n",
      "       [  1313],\n",
      "       [  2286],\n",
      "       [  3235],\n",
      "       [102250],\n",
      "       [164347],\n",
      "       [ 30934],\n",
      "       [ 94178],\n",
      "       [155705],\n",
      "       [  1494],\n",
      "       [201800],\n",
      "       [ 97434],\n",
      "       [142733],\n",
      "       [  1521],\n",
      "       [209358],\n",
      "       [ 49667],\n",
      "       [  8417],\n",
      "       [172462],\n",
      "       [224384],\n",
      "       [  1283],\n",
      "       [   620],\n",
      "       [  4787],\n",
      "       [191553],\n",
      "       [232928],\n",
      "       [147783],\n",
      "       [ 33872],\n",
      "       [235591],\n",
      "       [ 71133],\n",
      "       [125537],\n",
      "       [115494],\n",
      "       [  6324],\n",
      "       [   981],\n",
      "       [ 26396],\n",
      "       [149457],\n",
      "       [ 16447],\n",
      "       [ 41596],\n",
      "       [180803],\n",
      "       [ 14744],\n",
      "       [130906],\n",
      "       [ 69372],\n",
      "       [  3479],\n",
      "       [ 79231],\n",
      "       [165949],\n",
      "       [107961],\n",
      "       [247758],\n",
      "       [   120],\n",
      "       [   182],\n",
      "       [  1785],\n",
      "       [201405],\n",
      "       [235019],\n",
      "       [129406],\n",
      "       [134094],\n",
      "       [219693],\n",
      "       [ 56360],\n",
      "       [243048],\n",
      "       [132241],\n",
      "       [175211],\n",
      "       [ 51858],\n",
      "       [177774],\n",
      "       [213436],\n",
      "       [  4994],\n",
      "       [ 80565],\n",
      "       [ 66748],\n",
      "       [ 44307],\n",
      "       [ 67043],\n",
      "       [  3153],\n",
      "       [188961],\n",
      "       [238913],\n",
      "       [205379],\n",
      "       [   363],\n",
      "       [ 15396],\n",
      "       [109279],\n",
      "       [143530],\n",
      "       [193862],\n",
      "       [237632],\n",
      "       [233899],\n",
      "       [ 54801],\n",
      "       [ 89008],\n",
      "       [108244],\n",
      "       [220986],\n",
      "       [215669],\n",
      "       [196459],\n",
      "       [ 44904],\n",
      "       [142652],\n",
      "       [238039],\n",
      "       [ 73795],\n",
      "       [ 30288],\n",
      "       [251474],\n",
      "       [ 21287],\n",
      "       [ 50017],\n",
      "       [ 90991],\n",
      "       [250898],\n",
      "       [234824],\n",
      "       [232553],\n",
      "       [229235],\n",
      "       [ 89548],\n",
      "       [ 24869],\n",
      "       [ 12017]], dtype=int64), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
      "       0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
      "       0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32))\n",
      "(array([[  5709],\n",
      "       [   251],\n",
      "       [  5655],\n",
      "       [  8401],\n",
      "       [   270],\n",
      "       [ 12856],\n",
      "       [ 21379],\n",
      "       [    41],\n",
      "       [ 13680],\n",
      "       [   592],\n",
      "       [  1567],\n",
      "       [  1008],\n",
      "       [   533],\n",
      "       [   715],\n",
      "       [  2903],\n",
      "       [  1665],\n",
      "       [  2189],\n",
      "       [    35],\n",
      "       [  2155],\n",
      "       [   437],\n",
      "       [   243],\n",
      "       [  1482],\n",
      "       [ 36341],\n",
      "       [ 61183],\n",
      "       [ 16863],\n",
      "       [    99],\n",
      "       [   690],\n",
      "       [ 21545],\n",
      "       [  8774],\n",
      "       [  1011],\n",
      "       [  3238],\n",
      "       [ 11911],\n",
      "       [  1456],\n",
      "       [  6587],\n",
      "       [ 85787],\n",
      "       [  1236],\n",
      "       [  4112],\n",
      "       [   801],\n",
      "       [  1295],\n",
      "       [ 87408],\n",
      "       [   334],\n",
      "       [     0],\n",
      "       [  1211],\n",
      "       [  1387],\n",
      "       [   688],\n",
      "       [ 41355],\n",
      "       [  7721],\n",
      "       [  5545],\n",
      "       [  5441],\n",
      "       [ 34572],\n",
      "       [   199],\n",
      "       [ 12497],\n",
      "       [  1663],\n",
      "       [  1055],\n",
      "       [  5579],\n",
      "       [  1250],\n",
      "       [ 10564],\n",
      "       [  3942],\n",
      "       [  9954],\n",
      "       [ 20434],\n",
      "       [ 59014],\n",
      "       [  1865],\n",
      "       [ 10728],\n",
      "       [  2034],\n",
      "       [ 10248],\n",
      "       [  2205],\n",
      "       [   520],\n",
      "       [   174],\n",
      "       [150148],\n",
      "       [  3991],\n",
      "       [  1650],\n",
      "       [   120],\n",
      "       [   220],\n",
      "       [ 19320],\n",
      "       [  6537],\n",
      "       [  3928],\n",
      "       [  3119],\n",
      "       [   793],\n",
      "       [    78],\n",
      "       [  1085],\n",
      "       [     1],\n",
      "       [ 31639],\n",
      "       [ 13457],\n",
      "       [  6144],\n",
      "       [    20],\n",
      "       [  2596],\n",
      "       [   286],\n",
      "       [  1150],\n",
      "       [154749],\n",
      "       [  1617],\n",
      "       [  6505],\n",
      "       [  1392],\n",
      "       [    34],\n",
      "       [ 11884],\n",
      "       [   305],\n",
      "       [ 10013],\n",
      "       [ 10892],\n",
      "       [ 18933],\n",
      "       [106030],\n",
      "       [  2828],\n",
      "       [140911],\n",
      "       [  2354],\n",
      "       [   301],\n",
      "       [   501],\n",
      "       [   822],\n",
      "       [ 15710],\n",
      "       [   215],\n",
      "       [  2132],\n",
      "       [  1263],\n",
      "       [   543],\n",
      "       [152088],\n",
      "       [  4048],\n",
      "       [   400],\n",
      "       [  6693],\n",
      "       [  3932],\n",
      "       [  1262],\n",
      "       [  1081],\n",
      "       [   343],\n",
      "       [ 15006],\n",
      "       [ 12083],\n",
      "       [   231],\n",
      "       [  2153],\n",
      "       [   363],\n",
      "       [  1044],\n",
      "       [  7366],\n",
      "       [    17],\n",
      "       [  3198],\n",
      "       [   352]], dtype=int64), array([[244285],\n",
      "       [183494],\n",
      "       [168831],\n",
      "       [115668],\n",
      "       [  4076],\n",
      "       [159032],\n",
      "       [ 44072],\n",
      "       [   163],\n",
      "       [  7670],\n",
      "       [ 82363],\n",
      "       [ 69227],\n",
      "       [222401],\n",
      "       [ 22999],\n",
      "       [ 78303],\n",
      "       [137669],\n",
      "       [204235],\n",
      "       [ 83447],\n",
      "       [  3722],\n",
      "       [ 55816],\n",
      "       [221911],\n",
      "       [  1007],\n",
      "       [ 44072],\n",
      "       [239544],\n",
      "       [ 81111],\n",
      "       [244375],\n",
      "       [  8705],\n",
      "       [220018],\n",
      "       [  7619],\n",
      "       [189509],\n",
      "       [ 21894],\n",
      "       [ 29322],\n",
      "       [234835],\n",
      "       [119311],\n",
      "       [ 26311],\n",
      "       [156281],\n",
      "       [199631],\n",
      "       [  1925],\n",
      "       [218853],\n",
      "       [  2034],\n",
      "       [ 86851],\n",
      "       [183464],\n",
      "       [251618],\n",
      "       [ 93234],\n",
      "       [204679],\n",
      "       [162351],\n",
      "       [231964],\n",
      "       [ 65220],\n",
      "       [ 76196],\n",
      "       [128905],\n",
      "       [142692],\n",
      "       [133106],\n",
      "       [  1257],\n",
      "       [   345],\n",
      "       [115003],\n",
      "       [210584],\n",
      "       [   385],\n",
      "       [131847],\n",
      "       [236532],\n",
      "       [ 78398],\n",
      "       [ 24445],\n",
      "       [140546],\n",
      "       [171019],\n",
      "       [127907],\n",
      "       [102211],\n",
      "       [   903],\n",
      "       [ 10533],\n",
      "       [190721],\n",
      "       [   737],\n",
      "       [ 13726],\n",
      "       [ 59441],\n",
      "       [   337],\n",
      "       [   120],\n",
      "       [ 16591],\n",
      "       [180018],\n",
      "       [ 50030],\n",
      "       [  3928],\n",
      "       [176127],\n",
      "       [ 21006],\n",
      "       [202801],\n",
      "       [ 77690],\n",
      "       [134669],\n",
      "       [224909],\n",
      "       [219146],\n",
      "       [ 21121],\n",
      "       [215320],\n",
      "       [219247],\n",
      "       [223822],\n",
      "       [171093],\n",
      "       [ 79773],\n",
      "       [     0],\n",
      "       [213131],\n",
      "       [202685],\n",
      "       [208882],\n",
      "       [ 59996],\n",
      "       [ 54449],\n",
      "       [198591],\n",
      "       [ 79721],\n",
      "       [133530],\n",
      "       [231852],\n",
      "       [ 26028],\n",
      "       [   117],\n",
      "       [177740],\n",
      "       [ 83857],\n",
      "       [   980],\n",
      "       [220234],\n",
      "       [230129],\n",
      "       [ 73415],\n",
      "       [  7492],\n",
      "       [ 63486],\n",
      "       [    24],\n",
      "       [  6112],\n",
      "       [  1363],\n",
      "       [   732],\n",
      "       [249373],\n",
      "       [ 47484],\n",
      "       [199504],\n",
      "       [  1125],\n",
      "       [ 36133],\n",
      "       [154554],\n",
      "       [  5994],\n",
      "       [ 85486],\n",
      "       [237448],\n",
      "       [ 19963],\n",
      "       [ 57566],\n",
      "       [  7366],\n",
      "       [131898],\n",
      "       [196229],\n",
      "       [204823]], dtype=int64), array([0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "       1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
      "       0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
      "       1., 0., 0., 1., 0., 1., 0., 0., 0.], dtype=float32))\n",
      "(array([[  4142],\n",
      "       [  4536],\n",
      "       [ 65196],\n",
      "       [   837],\n",
      "       [  1490],\n",
      "       [ 20772],\n",
      "       [  2330],\n",
      "       [   106],\n",
      "       [ 21291],\n",
      "       [    14],\n",
      "       [  1885],\n",
      "       [ 18986],\n",
      "       [ 40117],\n",
      "       [  2341],\n",
      "       [  3796],\n",
      "       [   104],\n",
      "       [    87],\n",
      "       [  6064],\n",
      "       [  7296],\n",
      "       [   684],\n",
      "       [  1723],\n",
      "       [  7819],\n",
      "       [  6264],\n",
      "       [158881],\n",
      "       [  1501],\n",
      "       [    47],\n",
      "       [  9186],\n",
      "       [   113],\n",
      "       [  2382],\n",
      "       [   476],\n",
      "       [  5686],\n",
      "       [    68],\n",
      "       [  1267],\n",
      "       [  1094],\n",
      "       [  2457],\n",
      "       [     5],\n",
      "       [  4524],\n",
      "       [   297],\n",
      "       [  5238],\n",
      "       [   127],\n",
      "       [  2404],\n",
      "       [ 11122],\n",
      "       [   561],\n",
      "       [  1519],\n",
      "       [   702],\n",
      "       [  4608],\n",
      "       [  1043],\n",
      "       [   143],\n",
      "       [  3517],\n",
      "       [ 66500],\n",
      "       [ 14791],\n",
      "       [  4127],\n",
      "       [  1235],\n",
      "       [    60],\n",
      "       [ 66866],\n",
      "       [ 14869],\n",
      "       [    13],\n",
      "       [ 25001],\n",
      "       [  4408],\n",
      "       [ 45738],\n",
      "       [  5641],\n",
      "       [  9024],\n",
      "       [ 25982],\n",
      "       [     3],\n",
      "       [143230],\n",
      "       [    20],\n",
      "       [   188],\n",
      "       [  4859],\n",
      "       [ 13080],\n",
      "       [   265],\n",
      "       [    13],\n",
      "       [ 60294],\n",
      "       [ 24455],\n",
      "       [ 88277],\n",
      "       [ 47570],\n",
      "       [ 65636],\n",
      "       [  3773],\n",
      "       [  5275],\n",
      "       [   632],\n",
      "       [  1930],\n",
      "       [ 22050],\n",
      "       [ 28322],\n",
      "       [  7671],\n",
      "       [  2029],\n",
      "       [   718],\n",
      "       [  5426],\n",
      "       [ 13251],\n",
      "       [  6526],\n",
      "       [  6532],\n",
      "       [  3470],\n",
      "       [  3480],\n",
      "       [  2690],\n",
      "       [ 35191],\n",
      "       [  3714],\n",
      "       [  1585],\n",
      "       [ 10594],\n",
      "       [  3081],\n",
      "       [    28],\n",
      "       [   691],\n",
      "       [   713],\n",
      "       [  8473],\n",
      "       [   296],\n",
      "       [  5733],\n",
      "       [     1],\n",
      "       [  2409],\n",
      "       [   440],\n",
      "       [  1035],\n",
      "       [  1424],\n",
      "       [    50],\n",
      "       [   799],\n",
      "       [  1673],\n",
      "       [  9353],\n",
      "       [  1132],\n",
      "       [139766],\n",
      "       [   590],\n",
      "       [  1266],\n",
      "       [   461],\n",
      "       [   220],\n",
      "       [   157],\n",
      "       [  1744],\n",
      "       [   291],\n",
      "       [    47],\n",
      "       [    19],\n",
      "       [  3062],\n",
      "       [   477],\n",
      "       [  1416],\n",
      "       [   252],\n",
      "       [  2219]], dtype=int64), array([[167051],\n",
      "       [120399],\n",
      "       [ 22169],\n",
      "       [   240],\n",
      "       [ 12670],\n",
      "       [173267],\n",
      "       [ 54256],\n",
      "       [230100],\n",
      "       [ 88253],\n",
      "       [ 99012],\n",
      "       [ 79202],\n",
      "       [191368],\n",
      "       [ 30365],\n",
      "       [ 75537],\n",
      "       [104170],\n",
      "       [ 81772],\n",
      "       [227396],\n",
      "       [ 41074],\n",
      "       [201955],\n",
      "       [204392],\n",
      "       [190527],\n",
      "       [169898],\n",
      "       [135562],\n",
      "       [ 12918],\n",
      "       [117297],\n",
      "       [ 80121],\n",
      "       [110720],\n",
      "       [  3073],\n",
      "       [191633],\n",
      "       [184144],\n",
      "       [164975],\n",
      "       [163472],\n",
      "       [ 61619],\n",
      "       [240588],\n",
      "       [ 72602],\n",
      "       [235715],\n",
      "       [ 11341],\n",
      "       [185258],\n",
      "       [186675],\n",
      "       [  1739],\n",
      "       [ 79523],\n",
      "       [ 74169],\n",
      "       [ 20372],\n",
      "       [167622],\n",
      "       [231807],\n",
      "       [  2709],\n",
      "       [   300],\n",
      "       [190997],\n",
      "       [215483],\n",
      "       [ 11776],\n",
      "       [ 57166],\n",
      "       [ 10268],\n",
      "       [   798],\n",
      "       [ 24047],\n",
      "       [135358],\n",
      "       [232665],\n",
      "       [  3990],\n",
      "       [160478],\n",
      "       [220562],\n",
      "       [ 20838],\n",
      "       [ 62986],\n",
      "       [   533],\n",
      "       [ 11085],\n",
      "       [ 11822],\n",
      "       [253246],\n",
      "       [122139],\n",
      "       [131390],\n",
      "       [  1795],\n",
      "       [224657],\n",
      "       [    34],\n",
      "       [  4631],\n",
      "       [162332],\n",
      "       [175108],\n",
      "       [145846],\n",
      "       [172780],\n",
      "       [ 34352],\n",
      "       [ 61930],\n",
      "       [204787],\n",
      "       [132842],\n",
      "       [  1038],\n",
      "       [107708],\n",
      "       [   143],\n",
      "       [ 40583],\n",
      "       [ 55799],\n",
      "       [ 69575],\n",
      "       [114184],\n",
      "       [188594],\n",
      "       [204587],\n",
      "       [ 77626],\n",
      "       [ 92105],\n",
      "       [ 85932],\n",
      "       [  3472],\n",
      "       [193303],\n",
      "       [226799],\n",
      "       [ 51085],\n",
      "       [ 32215],\n",
      "       [   785],\n",
      "       [137691],\n",
      "       [104764],\n",
      "       [ 80361],\n",
      "       [178092],\n",
      "       [232777],\n",
      "       [112281],\n",
      "       [ 73110],\n",
      "       [ 31782],\n",
      "       [ 97962],\n",
      "       [ 48676],\n",
      "       [  2077],\n",
      "       [222518],\n",
      "       [ 89172],\n",
      "       [202649],\n",
      "       [108961],\n",
      "       [229036],\n",
      "       [ 14874],\n",
      "       [105215],\n",
      "       [ 10386],\n",
      "       [   796],\n",
      "       [ 19962],\n",
      "       [245159],\n",
      "       [ 28695],\n",
      "       [221645],\n",
      "       [180860],\n",
      "       [ 88135],\n",
      "       [ 86712],\n",
      "       [112376],\n",
      "       [ 20005],\n",
      "       [  2217],\n",
      "       [227387]], dtype=int64), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "       0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32))\n",
      "(array([[    73],\n",
      "       [  7129],\n",
      "       [     2],\n",
      "       [  6266],\n",
      "       [    27],\n",
      "       [  2767],\n",
      "       [  2163],\n",
      "       [  6742],\n",
      "       [ 13096],\n",
      "       [ 17422],\n",
      "       [  4224],\n",
      "       [   253],\n",
      "       [ 19360],\n",
      "       [   442],\n",
      "       [   288],\n",
      "       [ 47686],\n",
      "       [   151],\n",
      "       [  2561],\n",
      "       [  2669],\n",
      "       [   904],\n",
      "       [  6351],\n",
      "       [ 37505],\n",
      "       [  2782],\n",
      "       [  7841],\n",
      "       [   897],\n",
      "       [  1610],\n",
      "       [ 51701],\n",
      "       [ 13972],\n",
      "       [  7814],\n",
      "       [  2412],\n",
      "       [    47],\n",
      "       [   235],\n",
      "       [ 18170],\n",
      "       [   593],\n",
      "       [  6283],\n",
      "       [  3852],\n",
      "       [ 10469],\n",
      "       [  4430],\n",
      "       [ 28288],\n",
      "       [   421],\n",
      "       [  4100],\n",
      "       [  1441],\n",
      "       [   367],\n",
      "       [  1029],\n",
      "       [   249],\n",
      "       [ 40060],\n",
      "       [  3172],\n",
      "       [  2049],\n",
      "       [ 64532],\n",
      "       [   766],\n",
      "       [     6],\n",
      "       [   385],\n",
      "       [ 14435],\n",
      "       [  1243],\n",
      "       [  2607],\n",
      "       [   362],\n",
      "       [  1250],\n",
      "       [   252],\n",
      "       [   264],\n",
      "       [  9348],\n",
      "       [  1355],\n",
      "       [  1285],\n",
      "       [   930],\n",
      "       [ 11891],\n",
      "       [   715],\n",
      "       [    66],\n",
      "       [   772],\n",
      "       [  3723],\n",
      "       [  2358],\n",
      "       [   929],\n",
      "       [  1286],\n",
      "       [  1324],\n",
      "       [   121],\n",
      "       [  9585],\n",
      "       [ 33105],\n",
      "       [ 15688],\n",
      "       [  7546],\n",
      "       [  5620],\n",
      "       [     7],\n",
      "       [   590],\n",
      "       [   269],\n",
      "       [    22],\n",
      "       [ 13299],\n",
      "       [105999],\n",
      "       [ 38159],\n",
      "       [  2270],\n",
      "       [ 12245],\n",
      "       [  3187],\n",
      "       [     8],\n",
      "       [  9186],\n",
      "       [  2509],\n",
      "       [   950],\n",
      "       [    62],\n",
      "       [   605],\n",
      "       [   473],\n",
      "       [ 13134],\n",
      "       [102854],\n",
      "       [ 47165],\n",
      "       [    60],\n",
      "       [   181],\n",
      "       [ 23013],\n",
      "       [  3559],\n",
      "       [   173],\n",
      "       [  2629],\n",
      "       [    84],\n",
      "       [  3714],\n",
      "       [   478],\n",
      "       [  1801],\n",
      "       [  5712],\n",
      "       [   453],\n",
      "       [   464],\n",
      "       [  5856],\n",
      "       [    20],\n",
      "       [   585],\n",
      "       [  2585],\n",
      "       [   209],\n",
      "       [  7376],\n",
      "       [  2410],\n",
      "       [  1493],\n",
      "       [  5643],\n",
      "       [   189],\n",
      "       [  9330],\n",
      "       [  5795],\n",
      "       [  2134],\n",
      "       [   850],\n",
      "       [     0],\n",
      "       [  1511],\n",
      "       [  6467]], dtype=int64), array([[104409],\n",
      "       [ 50070],\n",
      "       [186254],\n",
      "       [ 13687],\n",
      "       [136525],\n",
      "       [ 31612],\n",
      "       [ 14719],\n",
      "       [ 86492],\n",
      "       [ 72157],\n",
      "       [109535],\n",
      "       [146786],\n",
      "       [ 77291],\n",
      "       [188172],\n",
      "       [101185],\n",
      "       [113346],\n",
      "       [ 22822],\n",
      "       [105869],\n",
      "       [143700],\n",
      "       [102749],\n",
      "       [139166],\n",
      "       [177260],\n",
      "       [ 20068],\n",
      "       [ 47251],\n",
      "       [118405],\n",
      "       [  4130],\n",
      "       [ 77311],\n",
      "       [  4500],\n",
      "       [228861],\n",
      "       [ 30869],\n",
      "       [206147],\n",
      "       [220301],\n",
      "       [117717],\n",
      "       [ 40450],\n",
      "       [194454],\n",
      "       [ 57460],\n",
      "       [243316],\n",
      "       [102842],\n",
      "       [208701],\n",
      "       [119939],\n",
      "       [ 65839],\n",
      "       [117146],\n",
      "       [ 19323],\n",
      "       [ 49875],\n",
      "       [ 92948],\n",
      "       [235377],\n",
      "       [107984],\n",
      "       [ 52019],\n",
      "       [ 37704],\n",
      "       [ 50417],\n",
      "       [   651],\n",
      "       [109984],\n",
      "       [     4],\n",
      "       [248019],\n",
      "       [ 73706],\n",
      "       [   104],\n",
      "       [   250],\n",
      "       [234269],\n",
      "       [ 82333],\n",
      "       [ 44037],\n",
      "       [ 26417],\n",
      "       [150994],\n",
      "       [ 31007],\n",
      "       [146658],\n",
      "       [150137],\n",
      "       [ 95065],\n",
      "       [185313],\n",
      "       [168087],\n",
      "       [ 29055],\n",
      "       [ 85724],\n",
      "       [243894],\n",
      "       [ 66560],\n",
      "       [110550],\n",
      "       [ 28996],\n",
      "       [253109],\n",
      "       [ 97523],\n",
      "       [ 17167],\n",
      "       [168452],\n",
      "       [   334],\n",
      "       [ 73053],\n",
      "       [185060],\n",
      "       [177524],\n",
      "       [ 30387],\n",
      "       [216043],\n",
      "       [ 78989],\n",
      "       [ 71746],\n",
      "       [ 44564],\n",
      "       [134906],\n",
      "       [159408],\n",
      "       [236550],\n",
      "       [220113],\n",
      "       [198086],\n",
      "       [ 51027],\n",
      "       [176465],\n",
      "       [214252],\n",
      "       [  4578],\n",
      "       [119696],\n",
      "       [ 45272],\n",
      "       [ 89133],\n",
      "       [180777],\n",
      "       [  3029],\n",
      "       [239116],\n",
      "       [140525],\n",
      "       [105445],\n",
      "       [ 14604],\n",
      "       [  1580],\n",
      "       [  2116],\n",
      "       [129714],\n",
      "       [ 25803],\n",
      "       [227511],\n",
      "       [    49],\n",
      "       [ 24677],\n",
      "       [ 66611],\n",
      "       [  3166],\n",
      "       [236836],\n",
      "       [186181],\n",
      "       [114556],\n",
      "       [121421],\n",
      "       [ 95144],\n",
      "       [ 45154],\n",
      "       [218365],\n",
      "       [ 50993],\n",
      "       [140526],\n",
      "       [164893],\n",
      "       [ 85099],\n",
      "       [   360],\n",
      "       [214706],\n",
      "       [208757],\n",
      "       [  7924]], dtype=int64), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "       1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "       1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 1., 0., 0., 1.], dtype=float32))\n",
      "(array([[  1523],\n",
      "       [  4045],\n",
      "       [  1474],\n",
      "       [  3350],\n",
      "       [    66],\n",
      "       [ 28266],\n",
      "       [   531],\n",
      "       [ 10938],\n",
      "       [  3103],\n",
      "       [  1988],\n",
      "       [ 10553],\n",
      "       [  4148],\n",
      "       [    62],\n",
      "       [   145],\n",
      "       [ 17694],\n",
      "       [  4317],\n",
      "       [   101],\n",
      "       [  2362],\n",
      "       [  3446],\n",
      "       [  1983],\n",
      "       [  1253],\n",
      "       [  2829],\n",
      "       [   227],\n",
      "       [  3021],\n",
      "       [   700],\n",
      "       [  2795],\n",
      "       [   358],\n",
      "       [  3247],\n",
      "       [  3584],\n",
      "       [  2423],\n",
      "       [  2304],\n",
      "       [ 23982],\n",
      "       [   122],\n",
      "       [  8022],\n",
      "       [  1177],\n",
      "       [   241],\n",
      "       [  2623],\n",
      "       [  3718],\n",
      "       [  6670],\n",
      "       [  3264],\n",
      "       [  2005],\n",
      "       [  1077],\n",
      "       [ 64844],\n",
      "       [  2276],\n",
      "       [ 15868],\n",
      "       [  5719],\n",
      "       [    11],\n",
      "       [ 17233],\n",
      "       [   860],\n",
      "       [  1450],\n",
      "       [139177],\n",
      "       [   213],\n",
      "       [ 52260],\n",
      "       [  6690],\n",
      "       [     8],\n",
      "       [  9499],\n",
      "       [  4500],\n",
      "       [  2810],\n",
      "       [ 17333],\n",
      "       [  1122],\n",
      "       [   116],\n",
      "       [  4346],\n",
      "       [  2809],\n",
      "       [  6683],\n",
      "       [   412],\n",
      "       [  4495],\n",
      "       [   707],\n",
      "       [135829],\n",
      "       [  2338],\n",
      "       [ 30702],\n",
      "       [  2173],\n",
      "       [ 30634],\n",
      "       [  1856],\n",
      "       [   868],\n",
      "       [   262],\n",
      "       [    38],\n",
      "       [   587],\n",
      "       [   610],\n",
      "       [   213],\n",
      "       [  2750],\n",
      "       [  2114],\n",
      "       [ 12113],\n",
      "       [    11],\n",
      "       [  2993],\n",
      "       [  6921],\n",
      "       [    79],\n",
      "       [   820],\n",
      "       [ 13373],\n",
      "       [  8122],\n",
      "       [  3987],\n",
      "       [ 15825],\n",
      "       [ 39367],\n",
      "       [    10],\n",
      "       [   421],\n",
      "       [  7684],\n",
      "       [ 15946],\n",
      "       [  4459],\n",
      "       [   332],\n",
      "       [  7163],\n",
      "       [    41],\n",
      "       [  8335],\n",
      "       [ 11787],\n",
      "       [ 10861],\n",
      "       [   817],\n",
      "       [  8864],\n",
      "       [  8088],\n",
      "       [149350],\n",
      "       [  5129],\n",
      "       [  1287],\n",
      "       [ 11071],\n",
      "       [   164],\n",
      "       [  3088],\n",
      "       [  3247],\n",
      "       [     4],\n",
      "       [  7427],\n",
      "       [  1042],\n",
      "       [ 21609],\n",
      "       [  8239],\n",
      "       [   849],\n",
      "       [  1647],\n",
      "       [  3991],\n",
      "       [   235],\n",
      "       [  3308],\n",
      "       [    19],\n",
      "       [  5141],\n",
      "       [   154],\n",
      "       [ 29940],\n",
      "       [     6]], dtype=int64), array([[100529],\n",
      "       [143555],\n",
      "       [  1280],\n",
      "       [187250],\n",
      "       [238799],\n",
      "       [ 29444],\n",
      "       [183301],\n",
      "       [250177],\n",
      "       [  5228],\n",
      "       [223454],\n",
      "       [ 99966],\n",
      "       [  6972],\n",
      "       [ 65822],\n",
      "       [206063],\n",
      "       [ 40704],\n",
      "       [171948],\n",
      "       [ 87444],\n",
      "       [172462],\n",
      "       [221938],\n",
      "       [206285],\n",
      "       [ 82306],\n",
      "       [174662],\n",
      "       [ 14234],\n",
      "       [128588],\n",
      "       [ 57472],\n",
      "       [ 85955],\n",
      "       [144689],\n",
      "       [250591],\n",
      "       [ 86834],\n",
      "       [192173],\n",
      "       [191330],\n",
      "       [194455],\n",
      "       [ 38438],\n",
      "       [103106],\n",
      "       [   369],\n",
      "       [    81],\n",
      "       [143687],\n",
      "       [251581],\n",
      "       [209295],\n",
      "       [139778],\n",
      "       [ 45416],\n",
      "       [ 18369],\n",
      "       [ 13611],\n",
      "       [220178],\n",
      "       [   997],\n",
      "       [126082],\n",
      "       [149455],\n",
      "       [162788],\n",
      "       [152237],\n",
      "       [101485],\n",
      "       [244532],\n",
      "       [224316],\n",
      "       [  5943],\n",
      "       [ 71576],\n",
      "       [183849],\n",
      "       [   395],\n",
      "       [ 48676],\n",
      "       [137741],\n",
      "       [ 29273],\n",
      "       [148575],\n",
      "       [151555],\n",
      "       [   148],\n",
      "       [128792],\n",
      "       [131146],\n",
      "       [229206],\n",
      "       [  1238],\n",
      "       [253800],\n",
      "       [218110],\n",
      "       [246407],\n",
      "       [ 88361],\n",
      "       [186756],\n",
      "       [ 77982],\n",
      "       [248575],\n",
      "       [103121],\n",
      "       [152170],\n",
      "       [157130],\n",
      "       [   561],\n",
      "       [ 49159],\n",
      "       [  1109],\n",
      "       [    26],\n",
      "       [178169],\n",
      "       [  8703],\n",
      "       [  4431],\n",
      "       [203549],\n",
      "       [109309],\n",
      "       [ 15211],\n",
      "       [101962],\n",
      "       [161199],\n",
      "       [222158],\n",
      "       [ 42759],\n",
      "       [  2577],\n",
      "       [ 87598],\n",
      "       [245699],\n",
      "       [213564],\n",
      "       [ 53619],\n",
      "       [176095],\n",
      "       [171831],\n",
      "       [245461],\n",
      "       [236129],\n",
      "       [  5124],\n",
      "       [ 81433],\n",
      "       [    68],\n",
      "       [ 43518],\n",
      "       [  3984],\n",
      "       [123042],\n",
      "       [ 78340],\n",
      "       [ 19868],\n",
      "       [ 84042],\n",
      "       [103128],\n",
      "       [137704],\n",
      "       [105671],\n",
      "       [212664],\n",
      "       [ 19634],\n",
      "       [ 71096],\n",
      "       [214923],\n",
      "       [ 27472],\n",
      "       [ 60855],\n",
      "       [237234],\n",
      "       [  1162],\n",
      "       [137273],\n",
      "       [   512],\n",
      "       [ 73511],\n",
      "       [ 23873],\n",
      "       [  5148],\n",
      "       [237497],\n",
      "       [ 48593],\n",
      "       [ 32466],\n",
      "       [  2703]], dtype=int64), array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "       0., 1., 1., 0., 1., 0., 0., 0., 0.], dtype=float32))\n",
      "(array([[  1857],\n",
      "       [146017],\n",
      "       [ 12628],\n",
      "       [ 18108],\n",
      "       [    54],\n",
      "       [ 15390],\n",
      "       [   475],\n",
      "       [     5],\n",
      "       [     6],\n",
      "       [ 25360],\n",
      "       [  3911],\n",
      "       [    19],\n",
      "       [ 67352],\n",
      "       [ 16213],\n",
      "       [   834],\n",
      "       [  2258],\n",
      "       [  1168],\n",
      "       [  2112],\n",
      "       [   107],\n",
      "       [  5795],\n",
      "       [ 47416],\n",
      "       [  1269],\n",
      "       [ 15222],\n",
      "       [ 21973],\n",
      "       [    22],\n",
      "       [  3436],\n",
      "       [   124],\n",
      "       [  1341],\n",
      "       [     7],\n",
      "       [  5418],\n",
      "       [  7128],\n",
      "       [  2231],\n",
      "       [    25],\n",
      "       [  1202],\n",
      "       [   427],\n",
      "       [ 55454],\n",
      "       [   556],\n",
      "       [ 51644],\n",
      "       [  4715],\n",
      "       [  4067],\n",
      "       [    50],\n",
      "       [ 11322],\n",
      "       [ 11900],\n",
      "       [  2655],\n",
      "       [  6961],\n",
      "       [   341],\n",
      "       [  8558],\n",
      "       [  4229],\n",
      "       [ 22597],\n",
      "       [ 64080],\n",
      "       [  1309],\n",
      "       [   985],\n",
      "       [  5909],\n",
      "       [   512],\n",
      "       [    12],\n",
      "       [  2513],\n",
      "       [   127],\n",
      "       [ 37929],\n",
      "       [   615],\n",
      "       [   109],\n",
      "       [  1084],\n",
      "       [  2513],\n",
      "       [ 10815],\n",
      "       [ 12950],\n",
      "       [ 38381],\n",
      "       [  2237],\n",
      "       [  2729],\n",
      "       [   627],\n",
      "       [  2332],\n",
      "       [  2957],\n",
      "       [     3],\n",
      "       [   397],\n",
      "       [106113],\n",
      "       [ 17344],\n",
      "       [  3271],\n",
      "       [   777],\n",
      "       [  3245],\n",
      "       [  3299],\n",
      "       [     8],\n",
      "       [    47],\n",
      "       [  2297],\n",
      "       [    14],\n",
      "       [  6395],\n",
      "       [    67],\n",
      "       [  7320],\n",
      "       [  5428],\n",
      "       [  1597],\n",
      "       [  2688],\n",
      "       [   641],\n",
      "       [   212],\n",
      "       [  6019],\n",
      "       [  3116],\n",
      "       [   714],\n",
      "       [  2562],\n",
      "       [    55],\n",
      "       [  8220],\n",
      "       [105147],\n",
      "       [105370],\n",
      "       [  8335],\n",
      "       [  2404],\n",
      "       [157650],\n",
      "       [  5824],\n",
      "       [  5662],\n",
      "       [  8500],\n",
      "       [  1592],\n",
      "       [ 10098],\n",
      "       [  1052],\n",
      "       [  5643],\n",
      "       [  1315],\n",
      "       [  3302],\n",
      "       [   228],\n",
      "       [  1857],\n",
      "       [ 21912],\n",
      "       [ 37467],\n",
      "       [ 11577],\n",
      "       [  1587],\n",
      "       [  1830],\n",
      "       [  2094],\n",
      "       [ 10491],\n",
      "       [  1917],\n",
      "       [  3515],\n",
      "       [    34],\n",
      "       [  5702],\n",
      "       [  4874],\n",
      "       [    20],\n",
      "       [ 28753],\n",
      "       [ 48497],\n",
      "       [  4032]], dtype=int64), array([[ 68746],\n",
      "       [160037],\n",
      "       [181863],\n",
      "       [190578],\n",
      "       [216091],\n",
      "       [   469],\n",
      "       [  1227],\n",
      "       [152078],\n",
      "       [    85],\n",
      "       [137545],\n",
      "       [242621],\n",
      "       [   149],\n",
      "       [218233],\n",
      "       [ 17092],\n",
      "       [228290],\n",
      "       [229635],\n",
      "       [ 98906],\n",
      "       [225560],\n",
      "       [ 49621],\n",
      "       [204340],\n",
      "       [     0],\n",
      "       [246426],\n",
      "       [ 23259],\n",
      "       [252702],\n",
      "       [157826],\n",
      "       [161132],\n",
      "       [121105],\n",
      "       [  3106],\n",
      "       [142506],\n",
      "       [117606],\n",
      "       [188972],\n",
      "       [191729],\n",
      "       [114490],\n",
      "       [138260],\n",
      "       [203304],\n",
      "       [197892],\n",
      "       [  6918],\n",
      "       [ 12459],\n",
      "       [  4762],\n",
      "       [196943],\n",
      "       [ 43036],\n",
      "       [154440],\n",
      "       [217807],\n",
      "       [184236],\n",
      "       [237200],\n",
      "       [123941],\n",
      "       [146444],\n",
      "       [ 89941],\n",
      "       [155749],\n",
      "       [ 94779],\n",
      "       [  7299],\n",
      "       [  5709],\n",
      "       [ 32569],\n",
      "       [ 92933],\n",
      "       [172959],\n",
      "       [251089],\n",
      "       [ 11779],\n",
      "       [129453],\n",
      "       [110318],\n",
      "       [  2621],\n",
      "       [ 96926],\n",
      "       [178450],\n",
      "       [187979],\n",
      "       [ 46541],\n",
      "       [  6105],\n",
      "       [     3],\n",
      "       [ 49101],\n",
      "       [  5223],\n",
      "       [ 30121],\n",
      "       [    82],\n",
      "       [ 31525],\n",
      "       [ 47600],\n",
      "       [148968],\n",
      "       [174647],\n",
      "       [178999],\n",
      "       [  1227],\n",
      "       [242661],\n",
      "       [131358],\n",
      "       [ 50872],\n",
      "       [122241],\n",
      "       [110641],\n",
      "       [   311],\n",
      "       [ 36304],\n",
      "       [ 12350],\n",
      "       [ 76192],\n",
      "       [  1013],\n",
      "       [131251],\n",
      "       [118954],\n",
      "       [178607],\n",
      "       [ 14136],\n",
      "       [124429],\n",
      "       [243983],\n",
      "       [   793],\n",
      "       [ 15445],\n",
      "       [ 60931],\n",
      "       [244833],\n",
      "       [175938],\n",
      "       [  1855],\n",
      "       [ 71600],\n",
      "       [ 86491],\n",
      "       [194884],\n",
      "       [  4000],\n",
      "       [224279],\n",
      "       [167718],\n",
      "       [173643],\n",
      "       [  1521],\n",
      "       [211499],\n",
      "       [  7547],\n",
      "       [104918],\n",
      "       [   727],\n",
      "       [214339],\n",
      "       [ 20051],\n",
      "       [145568],\n",
      "       [ 92720],\n",
      "       [130055],\n",
      "       [219094],\n",
      "       [169123],\n",
      "       [108310],\n",
      "       [ 58054],\n",
      "       [ 59174],\n",
      "       [ 24949],\n",
      "       [151720],\n",
      "       [ 71617],\n",
      "       [  4406],\n",
      "       [188114],\n",
      "       [ 18042],\n",
      "       [237375],\n",
      "       [ 83153]], dtype=int64), array([0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
      "       0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "       0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32))\n",
      "(array([[ 11307],\n",
      "       [  3082],\n",
      "       [  1559],\n",
      "       [   779],\n",
      "       [  5008],\n",
      "       [  2041],\n",
      "       [   424],\n",
      "       [  1624],\n",
      "       [   454],\n",
      "       [  4871],\n",
      "       [  3902],\n",
      "       [   664],\n",
      "       [    69],\n",
      "       [   158],\n",
      "       [  2966],\n",
      "       [    42],\n",
      "       [   294],\n",
      "       [ 50532],\n",
      "       [  7429],\n",
      "       [  1143],\n",
      "       [  5996],\n",
      "       [   303],\n",
      "       [   640],\n",
      "       [  2087],\n",
      "       [     1],\n",
      "       [  1218],\n",
      "       [   484],\n",
      "       [156522],\n",
      "       [  5798],\n",
      "       [   200],\n",
      "       [  1331],\n",
      "       [ 11268],\n",
      "       [  4626],\n",
      "       [  6489],\n",
      "       [154271],\n",
      "       [  1107],\n",
      "       [ 35543],\n",
      "       [   199],\n",
      "       [   515],\n",
      "       [  1579],\n",
      "       [  1332],\n",
      "       [   937],\n",
      "       [  3100],\n",
      "       [  2010],\n",
      "       [  1800],\n",
      "       [   107],\n",
      "       [  6470],\n",
      "       [  1653],\n",
      "       [  8618],\n",
      "       [   868],\n",
      "       [    30],\n",
      "       [    19],\n",
      "       [  2249],\n",
      "       [   219],\n",
      "       [ 27131],\n",
      "       [  4192],\n",
      "       [  1291],\n",
      "       [ 33477],\n",
      "       [   902],\n",
      "       [  9099],\n",
      "       [ 12245],\n",
      "       [  6328],\n",
      "       [    35],\n",
      "       [ 13362],\n",
      "       [   502],\n",
      "       [ 44636],\n",
      "       [   641],\n",
      "       [  9097],\n",
      "       [ 10182],\n",
      "       [    23],\n",
      "       [   260],\n",
      "       [  4138],\n",
      "       [     1],\n",
      "       [ 35279],\n",
      "       [  1193],\n",
      "       [   715],\n",
      "       [  4852],\n",
      "       [ 23969],\n",
      "       [  1741],\n",
      "       [  2185],\n",
      "       [   188],\n",
      "       [   747],\n",
      "       [  2761],\n",
      "       [   213],\n",
      "       [  7821],\n",
      "       [  8638],\n",
      "       [  6645],\n",
      "       [  1850],\n",
      "       [    33],\n",
      "       [  1769],\n",
      "       [  3175],\n",
      "       [   260],\n",
      "       [  1491],\n",
      "       [  3646],\n",
      "       [    51],\n",
      "       [  7221],\n",
      "       [   910],\n",
      "       [   755],\n",
      "       [   775],\n",
      "       [  6482],\n",
      "       [ 20125],\n",
      "       [   300],\n",
      "       [ 58650],\n",
      "       [ 13331],\n",
      "       [  4128],\n",
      "       [ 12927],\n",
      "       [   171],\n",
      "       [  2355],\n",
      "       [ 35143],\n",
      "       [141268],\n",
      "       [   668],\n",
      "       [   175],\n",
      "       [  3027],\n",
      "       [  5538],\n",
      "       [    58],\n",
      "       [    75],\n",
      "       [  2573],\n",
      "       [    20],\n",
      "       [  4990],\n",
      "       [136352],\n",
      "       [ 33958],\n",
      "       [  3141],\n",
      "       [  1362],\n",
      "       [ 10192],\n",
      "       [  7687],\n",
      "       [ 55354],\n",
      "       [  3524],\n",
      "       [  9155]], dtype=int64), array([[   164],\n",
      "       [ 81126],\n",
      "       [ 65374],\n",
      "       [ 78859],\n",
      "       [170066],\n",
      "       [213646],\n",
      "       [ 24885],\n",
      "       [118645],\n",
      "       [ 19448],\n",
      "       [238141],\n",
      "       [228425],\n",
      "       [     5],\n",
      "       [  6813],\n",
      "       [150683],\n",
      "       [ 55590],\n",
      "       [ 68233],\n",
      "       [228352],\n",
      "       [178140],\n",
      "       [231046],\n",
      "       [  1032],\n",
      "       [163905],\n",
      "       [101651],\n",
      "       [  9832],\n",
      "       [249808],\n",
      "       [ 21998],\n",
      "       [221888],\n",
      "       [231990],\n",
      "       [225590],\n",
      "       [122077],\n",
      "       [ 37900],\n",
      "       [ 73282],\n",
      "       [171719],\n",
      "       [ 39348],\n",
      "       [ 56027],\n",
      "       [  8740],\n",
      "       [ 27423],\n",
      "       [ 11635],\n",
      "       [247749],\n",
      "       [222493],\n",
      "       [158541],\n",
      "       [   688],\n",
      "       [ 11887],\n",
      "       [  1929],\n",
      "       [216099],\n",
      "       [109570],\n",
      "       [ 37024],\n",
      "       [ 36175],\n",
      "       [196531],\n",
      "       [121940],\n",
      "       [ 10288],\n",
      "       [  8807],\n",
      "       [     9],\n",
      "       [131085],\n",
      "       [  2108],\n",
      "       [ 54314],\n",
      "       [186572],\n",
      "       [217331],\n",
      "       [ 13765],\n",
      "       [ 32918],\n",
      "       [200709],\n",
      "       [  1086],\n",
      "       [ 42813],\n",
      "       [ 91994],\n",
      "       [ 94795],\n",
      "       [103346],\n",
      "       [ 49039],\n",
      "       [201194],\n",
      "       [155820],\n",
      "       [ 62415],\n",
      "       [170253],\n",
      "       [ 41064],\n",
      "       [151170],\n",
      "       [215470],\n",
      "       [119358],\n",
      "       [113062],\n",
      "       [     2],\n",
      "       [  1183],\n",
      "       [212908],\n",
      "       [177323],\n",
      "       [180540],\n",
      "       [218416],\n",
      "       [     6],\n",
      "       [    38],\n",
      "       [143275],\n",
      "       [149827],\n",
      "       [205628],\n",
      "       [128787],\n",
      "       [ 97990],\n",
      "       [ 71985],\n",
      "       [117479],\n",
      "       [ 34951],\n",
      "       [  7767],\n",
      "       [ 47523],\n",
      "       [ 15660],\n",
      "       [249586],\n",
      "       [181220],\n",
      "       [103902],\n",
      "       [121782],\n",
      "       [205510],\n",
      "       [ 24043],\n",
      "       [174292],\n",
      "       [231125],\n",
      "       [162361],\n",
      "       [183771],\n",
      "       [     0],\n",
      "       [    63],\n",
      "       [  6995],\n",
      "       [   117],\n",
      "       [117425],\n",
      "       [176007],\n",
      "       [ 58865],\n",
      "       [115383],\n",
      "       [  1787],\n",
      "       [   513],\n",
      "       [ 31936],\n",
      "       [ 69212],\n",
      "       [   863],\n",
      "       [149870],\n",
      "       [121430],\n",
      "       [224809],\n",
      "       [204700],\n",
      "       [125008],\n",
      "       [ 66550],\n",
      "       [197873],\n",
      "       [161192],\n",
      "       [ 61656],\n",
      "       [  1152],\n",
      "       [ 12125]], dtype=int64), array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "       0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "       0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 1., 1.], dtype=float32))\n",
      "(array([[140538],\n",
      "       [  1404],\n",
      "       [   200],\n",
      "       [   274],\n",
      "       [ 39550],\n",
      "       [     0],\n",
      "       [    44],\n",
      "       [  1511],\n",
      "       [  3530],\n",
      "       [    20],\n",
      "       [  1578],\n",
      "       [  1275],\n",
      "       [  2111],\n",
      "       [    21],\n",
      "       [  2426],\n",
      "       [ 15923],\n",
      "       [ 46044],\n",
      "       [    23],\n",
      "       [  4614],\n",
      "       [  6190],\n",
      "       [  1297],\n",
      "       [  2245],\n",
      "       [  3062],\n",
      "       [    85],\n",
      "       [  2470],\n",
      "       [     9],\n",
      "       [  5575],\n",
      "       [   431],\n",
      "       [  2263],\n",
      "       [   139],\n",
      "       [  1347],\n",
      "       [  5325],\n",
      "       [  1678],\n",
      "       [    18],\n",
      "       [  4993],\n",
      "       [    64],\n",
      "       [  4121],\n",
      "       [  4505],\n",
      "       [  7768],\n",
      "       [  1078],\n",
      "       [  3489],\n",
      "       [  1577],\n",
      "       [ 76163],\n",
      "       [  4212],\n",
      "       [  1666],\n",
      "       [  1149],\n",
      "       [  6255],\n",
      "       [   509],\n",
      "       [ 25328],\n",
      "       [  2835],\n",
      "       [   964],\n",
      "       [   717],\n",
      "       [  5254],\n",
      "       [  3129],\n",
      "       [  1751],\n",
      "       [  2304],\n",
      "       [ 14575],\n",
      "       [   694],\n",
      "       [ 30257],\n",
      "       [   451],\n",
      "       [  3074],\n",
      "       [   645],\n",
      "       [   680],\n",
      "       [   770],\n",
      "       [  3654],\n",
      "       [   585],\n",
      "       [  2419],\n",
      "       [  1833],\n",
      "       [  1594],\n",
      "       [   216],\n",
      "       [   971],\n",
      "       [ 24039],\n",
      "       [  1264],\n",
      "       [   786],\n",
      "       [ 88147],\n",
      "       [ 72820],\n",
      "       [ 10113],\n",
      "       [     4],\n",
      "       [   760],\n",
      "       [   904],\n",
      "       [  2097],\n",
      "       [     1],\n",
      "       [  3367],\n",
      "       [     5],\n",
      "       [    33],\n",
      "       [  5048],\n",
      "       [  9853],\n",
      "       [  1446],\n",
      "       [  9428],\n",
      "       [ 10983],\n",
      "       [   488],\n",
      "       [   697],\n",
      "       [  2080],\n",
      "       [ 26655],\n",
      "       [   408],\n",
      "       [    40],\n",
      "       [   961],\n",
      "       [  6757],\n",
      "       [    26],\n",
      "       [  1235],\n",
      "       [ 23466],\n",
      "       [  1635],\n",
      "       [  1043],\n",
      "       [ 71617],\n",
      "       [  2059],\n",
      "       [    33],\n",
      "       [   540],\n",
      "       [109893],\n",
      "       [  2190],\n",
      "       [   253],\n",
      "       [  1045],\n",
      "       [  1197],\n",
      "       [   202],\n",
      "       [   610],\n",
      "       [  4171],\n",
      "       [ 19844],\n",
      "       [ 59604],\n",
      "       [  3400],\n",
      "       [  3745],\n",
      "       [  1527],\n",
      "       [  9081],\n",
      "       [  7060],\n",
      "       [  3363],\n",
      "       [142056],\n",
      "       [   489],\n",
      "       [   779],\n",
      "       [  1394],\n",
      "       [   486]], dtype=int64), array([[  3912],\n",
      "       [ 33722],\n",
      "       [  5343],\n",
      "       [147240],\n",
      "       [ 16211],\n",
      "       [198944],\n",
      "       [118636],\n",
      "       [  4472],\n",
      "       [175597],\n",
      "       [108108],\n",
      "       [131601],\n",
      "       [242157],\n",
      "       [241465],\n",
      "       [     6],\n",
      "       [ 18569],\n",
      "       [213234],\n",
      "       [115921],\n",
      "       [185245],\n",
      "       [ 16056],\n",
      "       [ 94025],\n",
      "       [ 12014],\n",
      "       [156912],\n",
      "       [   872],\n",
      "       [214413],\n",
      "       [168734],\n",
      "       [    16],\n",
      "       [162852],\n",
      "       [ 20246],\n",
      "       [102024],\n",
      "       [ 53642],\n",
      "       [ 34000],\n",
      "       [  5325],\n",
      "       [139774],\n",
      "       [249111],\n",
      "       [ 76970],\n",
      "       [   530],\n",
      "       [172519],\n",
      "       [  1209],\n",
      "       [ 78915],\n",
      "       [162932],\n",
      "       [ 96550],\n",
      "       [ 45343],\n",
      "       [192974],\n",
      "       [182536],\n",
      "       [  4913],\n",
      "       [243440],\n",
      "       [   379],\n",
      "       [ 93635],\n",
      "       [131553],\n",
      "       [178604],\n",
      "       [243747],\n",
      "       [117133],\n",
      "       [180662],\n",
      "       [198480],\n",
      "       [    27],\n",
      "       [  6920],\n",
      "       [ 95589],\n",
      "       [  3052],\n",
      "       [ 22779],\n",
      "       [110812],\n",
      "       [198462],\n",
      "       [120461],\n",
      "       [  9242],\n",
      "       [ 86564],\n",
      "       [ 23952],\n",
      "       [244480],\n",
      "       [220394],\n",
      "       [145686],\n",
      "       [242232],\n",
      "       [  6893],\n",
      "       [ 57951],\n",
      "       [ 52643],\n",
      "       [240030],\n",
      "       [114298],\n",
      "       [184033],\n",
      "       [106155],\n",
      "       [177959],\n",
      "       [188892],\n",
      "       [209692],\n",
      "       [100698],\n",
      "       [   965],\n",
      "       [ 51703],\n",
      "       [ 11245],\n",
      "       [235686],\n",
      "       [ 59349],\n",
      "       [176965],\n",
      "       [ 36142],\n",
      "       [ 89307],\n",
      "       [212508],\n",
      "       [235349],\n",
      "       [187024],\n",
      "       [ 21255],\n",
      "       [ 25183],\n",
      "       [150236],\n",
      "       [181285],\n",
      "       [175707],\n",
      "       [132442],\n",
      "       [211518],\n",
      "       [  3365],\n",
      "       [176993],\n",
      "       [186893],\n",
      "       [ 98954],\n",
      "       [169580],\n",
      "       [ 50382],\n",
      "       [ 62968],\n",
      "       [173036],\n",
      "       [ 12665],\n",
      "       [ 29280],\n",
      "       [  2892],\n",
      "       [   501],\n",
      "       [ 18312],\n",
      "       [154897],\n",
      "       [136462],\n",
      "       [ 27834],\n",
      "       [208708],\n",
      "       [125509],\n",
      "       [134758],\n",
      "       [134694],\n",
      "       [ 17798],\n",
      "       [129338],\n",
      "       [ 39815],\n",
      "       [180439],\n",
      "       [  7351],\n",
      "       [  7717],\n",
      "       [ 56137],\n",
      "       [175695],\n",
      "       [173462],\n",
      "       [ 58602]], dtype=int64), array([1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "       0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32))\n",
      "(array([[  2957],\n",
      "       [   705],\n",
      "       [ 44974],\n",
      "       [  9228],\n",
      "       [   339],\n",
      "       [    19],\n",
      "       [ 67426],\n",
      "       [  4517],\n",
      "       [   635],\n",
      "       [    56],\n",
      "       [   841],\n",
      "       [ 16271],\n",
      "       [     1],\n",
      "       [ 14251],\n",
      "       [  2578],\n",
      "       [ 14320],\n",
      "       [ 11089],\n",
      "       [  3510],\n",
      "       [  1031],\n",
      "       [  3270],\n",
      "       [  1055],\n",
      "       [     7],\n",
      "       [   207],\n",
      "       [    18],\n",
      "       [   379],\n",
      "       [ 15613],\n",
      "       [   684],\n",
      "       [   598],\n",
      "       [    81],\n",
      "       [    23],\n",
      "       [  4614],\n",
      "       [  2210],\n",
      "       [  1314],\n",
      "       [ 10929],\n",
      "       [ 14940],\n",
      "       [  2582],\n",
      "       [ 19526],\n",
      "       [  3455],\n",
      "       [  4804],\n",
      "       [   408],\n",
      "       [  3628],\n",
      "       [ 23843],\n",
      "       [   413],\n",
      "       [   823],\n",
      "       [  1079],\n",
      "       [   477],\n",
      "       [  5450],\n",
      "       [   995],\n",
      "       [ 47417],\n",
      "       [   939],\n",
      "       [  2670],\n",
      "       [ 17698],\n",
      "       [  8202],\n",
      "       [  3602],\n",
      "       [  2824],\n",
      "       [ 37646],\n",
      "       [   265],\n",
      "       [  2680],\n",
      "       [    11],\n",
      "       [  5890],\n",
      "       [  1811],\n",
      "       [  2585],\n",
      "       [ 12020],\n",
      "       [  8166],\n",
      "       [  1917],\n",
      "       [  5473],\n",
      "       [   126],\n",
      "       [    69],\n",
      "       [  4879],\n",
      "       [  6100],\n",
      "       [   101],\n",
      "       [   400],\n",
      "       [  5473],\n",
      "       [  8581],\n",
      "       [ 11324],\n",
      "       [ 33427],\n",
      "       [  1267],\n",
      "       [ 36326],\n",
      "       [   236],\n",
      "       [  6520],\n",
      "       [     4],\n",
      "       [   225],\n",
      "       [  9647],\n",
      "       [   379],\n",
      "       [  9044],\n",
      "       [  1016],\n",
      "       [ 11509],\n",
      "       [ 64764],\n",
      "       [152349],\n",
      "       [   136],\n",
      "       [  2209],\n",
      "       [ 14345],\n",
      "       [  1824],\n",
      "       [  3101],\n",
      "       [  8080],\n",
      "       [   386],\n",
      "       [   136],\n",
      "       [   367],\n",
      "       [  6935],\n",
      "       [  2101],\n",
      "       [ 12328],\n",
      "       [ 10535],\n",
      "       [   328],\n",
      "       [ 11343],\n",
      "       [   724],\n",
      "       [    26],\n",
      "       [  4268],\n",
      "       [   397],\n",
      "       [   915],\n",
      "       [  2611],\n",
      "       [     2],\n",
      "       [   303],\n",
      "       [  3588],\n",
      "       [    19],\n",
      "       [   130],\n",
      "       [    15],\n",
      "       [ 21251],\n",
      "       [ 24509],\n",
      "       [   704],\n",
      "       [  4186],\n",
      "       [  5308],\n",
      "       [   271],\n",
      "       [  3265],\n",
      "       [    84],\n",
      "       [  1556],\n",
      "       [   443],\n",
      "       [   500],\n",
      "       [   941]], dtype=int64), array([[ 11494],\n",
      "       [  3788],\n",
      "       [227890],\n",
      "       [208997],\n",
      "       [ 43028],\n",
      "       [  8285],\n",
      "       [ 87079],\n",
      "       [ 25759],\n",
      "       [ 47218],\n",
      "       [231442],\n",
      "       [  3157],\n",
      "       [148856],\n",
      "       [  1498],\n",
      "       [138071],\n",
      "       [ 58740],\n",
      "       [122203],\n",
      "       [115065],\n",
      "       [  2444],\n",
      "       [ 21385],\n",
      "       [ 82669],\n",
      "       [180949],\n",
      "       [ 52222],\n",
      "       [ 54314],\n",
      "       [112477],\n",
      "       [196735],\n",
      "       [169731],\n",
      "       [227393],\n",
      "       [  7849],\n",
      "       [135296],\n",
      "       [ 47065],\n",
      "       [ 83774],\n",
      "       [ 18807],\n",
      "       [187886],\n",
      "       [136729],\n",
      "       [  5623],\n",
      "       [ 41933],\n",
      "       [195750],\n",
      "       [241896],\n",
      "       [206587],\n",
      "       [    17],\n",
      "       [ 16621],\n",
      "       [ 19812],\n",
      "       [  7352],\n",
      "       [205236],\n",
      "       [  1708],\n",
      "       [214923],\n",
      "       [  1357],\n",
      "       [184527],\n",
      "       [   662],\n",
      "       [106023],\n",
      "       [ 72309],\n",
      "       [245300],\n",
      "       [ 28315],\n",
      "       [252163],\n",
      "       [ 96717],\n",
      "       [210048],\n",
      "       [139651],\n",
      "       [126873],\n",
      "       [ 95732],\n",
      "       [245753],\n",
      "       [ 83962],\n",
      "       [199230],\n",
      "       [139201],\n",
      "       [  7547],\n",
      "       [ 10490],\n",
      "       [215438],\n",
      "       [   679],\n",
      "       [ 26493],\n",
      "       [ 59024],\n",
      "       [203205],\n",
      "       [    77],\n",
      "       [232678],\n",
      "       [  5451],\n",
      "       [252236],\n",
      "       [  2223],\n",
      "       [ 35803],\n",
      "       [ 75858],\n",
      "       [ 72558],\n",
      "       [220870],\n",
      "       [111001],\n",
      "       [125324],\n",
      "       [  1995],\n",
      "       [  6931],\n",
      "       [ 82665],\n",
      "       [   155],\n",
      "       [   628],\n",
      "       [250204],\n",
      "       [ 70985],\n",
      "       [161911],\n",
      "       [  3099],\n",
      "       [  5045],\n",
      "       [217047],\n",
      "       [233311],\n",
      "       [  3101],\n",
      "       [153586],\n",
      "       [ 83570],\n",
      "       [  6603],\n",
      "       [ 54402],\n",
      "       [230158],\n",
      "       [197387],\n",
      "       [105350],\n",
      "       [ 63988],\n",
      "       [ 96008],\n",
      "       [233757],\n",
      "       [192590],\n",
      "       [   401],\n",
      "       [ 28414],\n",
      "       [141868],\n",
      "       [ 30482],\n",
      "       [ 16642],\n",
      "       [ 57732],\n",
      "       [ 66743],\n",
      "       [196758],\n",
      "       [101963],\n",
      "       [  1058],\n",
      "       [     1],\n",
      "       [ 43677],\n",
      "       [177049],\n",
      "       [  1660],\n",
      "       [171324],\n",
      "       [    24],\n",
      "       [233812],\n",
      "       [229095],\n",
      "       [  1819],\n",
      "       [     2],\n",
      "       [235333],\n",
      "       [  1338],\n",
      "       [ 92339]], dtype=int64), array([1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "       0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
      "       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "       0., 1., 0., 0., 1., 1., 0., 1., 0.], dtype=float32))\n",
      "(array([[   263],\n",
      "       [  2669],\n",
      "       [   355],\n",
      "       [  1745],\n",
      "       [  1665],\n",
      "       [  4538],\n",
      "       [   307],\n",
      "       [  1746],\n",
      "       [   351],\n",
      "       [   111],\n",
      "       [ 33962],\n",
      "       [    12],\n",
      "       [ 26606],\n",
      "       [    69],\n",
      "       [  7937],\n",
      "       [  6205],\n",
      "       [   557],\n",
      "       [   285],\n",
      "       [     9],\n",
      "       [    35],\n",
      "       [  1200],\n",
      "       [    96],\n",
      "       [  2255],\n",
      "       [  3490],\n",
      "       [   994],\n",
      "       [  9522],\n",
      "       [   532],\n",
      "       [  3838],\n",
      "       [ 10058],\n",
      "       [   421],\n",
      "       [  8868],\n",
      "       [  5071],\n",
      "       [  3091],\n",
      "       [   606],\n",
      "       [  3939],\n",
      "       [ 24960],\n",
      "       [  2202],\n",
      "       [  2168],\n",
      "       [  1150],\n",
      "       [    35],\n",
      "       [  5734],\n",
      "       [  3405],\n",
      "       [ 54132],\n",
      "       [  1242],\n",
      "       [  4278],\n",
      "       [  3694],\n",
      "       [    76],\n",
      "       [   733],\n",
      "       [   125],\n",
      "       [  1053],\n",
      "       [  1462],\n",
      "       [    53],\n",
      "       [ 27080],\n",
      "       [   223],\n",
      "       [ 29540],\n",
      "       [  2929],\n",
      "       [    43],\n",
      "       [  4764],\n",
      "       [  1719],\n",
      "       [ 15892],\n",
      "       [    38],\n",
      "       [  3473],\n",
      "       [  3806],\n",
      "       [  6363],\n",
      "       [  7515],\n",
      "       [   742],\n",
      "       [   687],\n",
      "       [   898],\n",
      "       [    11],\n",
      "       [    24],\n",
      "       [   583],\n",
      "       [  1969],\n",
      "       [137802],\n",
      "       [ 37170],\n",
      "       [ 51301],\n",
      "       [  5354],\n",
      "       [ 13265],\n",
      "       [ 63740],\n",
      "       [  1997],\n",
      "       [   401],\n",
      "       [   742],\n",
      "       [    87],\n",
      "       [156295],\n",
      "       [ 37758],\n",
      "       [  6187],\n",
      "       [ 51355],\n",
      "       [  3639],\n",
      "       [  4336],\n",
      "       [  1610],\n",
      "       [   582],\n",
      "       [  6204],\n",
      "       [ 88646],\n",
      "       [ 10328],\n",
      "       [   306],\n",
      "       [   588],\n",
      "       [  1980],\n",
      "       [ 26939],\n",
      "       [ 65818],\n",
      "       [  3464],\n",
      "       [   436],\n",
      "       [ 12307],\n",
      "       [  2474],\n",
      "       [ 29277],\n",
      "       [  2023],\n",
      "       [   318],\n",
      "       [  3979],\n",
      "       [  4796],\n",
      "       [   582],\n",
      "       [  1952],\n",
      "       [   911],\n",
      "       [    42],\n",
      "       [  2150],\n",
      "       [153537],\n",
      "       [  1342],\n",
      "       [  1359],\n",
      "       [  2006],\n",
      "       [    41],\n",
      "       [  1455],\n",
      "       [    45],\n",
      "       [    25],\n",
      "       [ 44771],\n",
      "       [   112],\n",
      "       [   856],\n",
      "       [   307],\n",
      "       [  2122],\n",
      "       [ 32200],\n",
      "       [   851],\n",
      "       [  8422]], dtype=int64), array([[155822],\n",
      "       [137375],\n",
      "       [  2089],\n",
      "       [  1653],\n",
      "       [173311],\n",
      "       [234972],\n",
      "       [208464],\n",
      "       [ 16446],\n",
      "       [ 20230],\n",
      "       [ 86502],\n",
      "       [   139],\n",
      "       [131715],\n",
      "       [181504],\n",
      "       [  8023],\n",
      "       [  8358],\n",
      "       [   125],\n",
      "       [ 68835],\n",
      "       [  1330],\n",
      "       [246607],\n",
      "       [ 59205],\n",
      "       [ 59931],\n",
      "       [ 48257],\n",
      "       [232333],\n",
      "       [165182],\n",
      "       [ 14717],\n",
      "       [190161],\n",
      "       [201835],\n",
      "       [  1422],\n",
      "       [124374],\n",
      "       [250361],\n",
      "       [ 22204],\n",
      "       [  5002],\n",
      "       [   339],\n",
      "       [ 86684],\n",
      "       [ 83824],\n",
      "       [251816],\n",
      "       [   656],\n",
      "       [  5793],\n",
      "       [244627],\n",
      "       [164278],\n",
      "       [ 37306],\n",
      "       [ 22153],\n",
      "       [  1191],\n",
      "       [   248],\n",
      "       [159936],\n",
      "       [157603],\n",
      "       [ 62858],\n",
      "       [ 14518],\n",
      "       [244252],\n",
      "       [163918],\n",
      "       [185480],\n",
      "       [136165],\n",
      "       [ 43070],\n",
      "       [    28],\n",
      "       [111374],\n",
      "       [163158],\n",
      "       [ 12903],\n",
      "       [174106],\n",
      "       [ 56786],\n",
      "       [195965],\n",
      "       [    65],\n",
      "       [ 43285],\n",
      "       [177680],\n",
      "       [ 57931],\n",
      "       [ 58339],\n",
      "       [ 78729],\n",
      "       [124819],\n",
      "       [106671],\n",
      "       [114401],\n",
      "       [   428],\n",
      "       [184303],\n",
      "       [ 42154],\n",
      "       [124502],\n",
      "       [179271],\n",
      "       [225589],\n",
      "       [220857],\n",
      "       [ 85736],\n",
      "       [ 68890],\n",
      "       [144360],\n",
      "       [   970],\n",
      "       [   980],\n",
      "       [ 82382],\n",
      "       [ 92289],\n",
      "       [226137],\n",
      "       [214113],\n",
      "       [118414],\n",
      "       [246161],\n",
      "       [216602],\n",
      "       [150124],\n",
      "       [   943],\n",
      "       [    49],\n",
      "       [171680],\n",
      "       [115481],\n",
      "       [151881],\n",
      "       [ 31975],\n",
      "       [ 78376],\n",
      "       [104994],\n",
      "       [228295],\n",
      "       [202410],\n",
      "       [110519],\n",
      "       [170757],\n",
      "       [  3970],\n",
      "       [   483],\n",
      "       [225148],\n",
      "       [135964],\n",
      "       [217261],\n",
      "       [106572],\n",
      "       [ 52061],\n",
      "       [  7366],\n",
      "       [ 86276],\n",
      "       [149219],\n",
      "       [ 48242],\n",
      "       [111916],\n",
      "       [238391],\n",
      "       [160109],\n",
      "       [  4622],\n",
      "       [121030],\n",
      "       [190291],\n",
      "       [191324],\n",
      "       [167565],\n",
      "       [217268],\n",
      "       [    10],\n",
      "       [ 81262],\n",
      "       [197955],\n",
      "       [211825],\n",
      "       [152610],\n",
      "       [195956],\n",
      "       [217357]], dtype=int64), array([0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1.,\n",
      "       0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "# 构造mini-batch，准备对模型进行训练\n",
    "# 我们将不同类型的数据放到不同的tensor里，便于神经网络进行处理\n",
    "# 并通过numpy的array函数，构造出不同的tensor来，并把这些tensor送入神经网络中进行训练\n",
    "def build_batch(dataset, batch_size, epoch_num):\n",
    "    \n",
    "    # center_word_batch缓存batch_size个中心词\n",
    "    center_word_batch = []\n",
    "    # target_word_batch缓存batch_size个目标词（可以是正样本或者负样本）\n",
    "    target_word_batch = []\n",
    "    # label_batch缓存了batch_size个0或1的标签，用于模型训练\n",
    "    label_batch = []\n",
    "\n",
    "    for epoch in range(epoch_num):\n",
    "        # 每次开启一个新epoch之前，都对数据进行一次随机打乱，提高训练效果\n",
    "        random.shuffle(dataset)\n",
    "        \n",
    "        for center_word, target_word, label in dataset:\n",
    "            # 遍历dataset中的每个样本，并将这些数据送到不同的tensor里\n",
    "            center_word_batch.append([center_word])\n",
    "            target_word_batch.append([target_word])\n",
    "            label_batch.append(label)\n",
    "\n",
    "            # 当样本积攒到一个batch_size后，我们把数据都返回回来\n",
    "            # 在这里我们使用numpy的array函数把list封装成tensor\n",
    "            # 并使用python的迭代器机制，将数据yield出来\n",
    "            # 使用迭代器的好处是可以节省内存\n",
    "            if len(center_word_batch) == batch_size:\n",
    "                yield np.array(center_word_batch).astype(\"int64\"), \\\n",
    "                    np.array(target_word_batch).astype(\"int64\"), \\\n",
    "                    np.array(label_batch).astype(\"float32\")\n",
    "                center_word_batch = []\n",
    "                target_word_batch = []\n",
    "                label_batch = []\n",
    "\n",
    "    if len(center_word_batch) > 0:\n",
    "        yield np.array(center_word_batch).astype(\"int64\"), \\\n",
    "            np.array(target_word_batch).astype(\"int64\"), \\\n",
    "            np.array(label_batch).astype(\"float32\")\n",
    "\n",
    "for _, batch in zip(range(10), build_batch(dataset, 128, 3)):\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df68d42b",
   "metadata": {},
   "source": [
    "在飞桨动态图中，对于任意网络，都需要定义一个继承自paddle.nn.layer的类来搭建网络结构、参数等数据的声明。同时需要在forward函数中定义网络的计算逻辑。值得注意的是，我们仅需要定义网络的前向计算逻辑，飞桨会自动完成神经网络的后向计算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef47b08",
   "metadata": {},
   "source": [
    "在skip-gram的网络结构中，使用的最关键的APi是paddle.nn.Embedding函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d6a1aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义skip-gram训练网络结构\n",
    "#使用paddlepaddle的2.0.0版本\n",
    "#一般来说，在使用paddle训练的时候，我们需要通过一个类来定义网络结构，这个类继承了paddle.nn.layer\n",
    "class SkipGram(paddle.nn.Layer):\n",
    "    def __init__(self, vocab_size, embedding_size, init_scale=0.1):\n",
    "        # vocab_size定义了这个skipgram这个模型的词表大小\n",
    "        # embedding_size定义了词向量的维度是多少\n",
    "        # init_scale定义了词向量初始化的范围，一般来说，比较小的初始化范围有助于模型训练\n",
    "        super(SkipGram, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        # 使用Embedding函数构造一个词向量参数\n",
    "        # 这个参数的大小为：[self.vocab_size, self.embedding_size]\n",
    "        # 数据类型为：float32\n",
    "        # 这个参数的初始化方式为在[-init_scale, init_scale]区间进行均匀采样\n",
    "        self.embedding = Embedding(num_embeddings = self.vocab_size,embedding_dim = self.embedding_size,weight_attr=paddle.ParamAttr(initializer=paddle.nn.initializer.Uniform(low=-init_scale, high=init_scale)))\n",
    "\n",
    "        # 使用Embedding函数构造另外一个词向量参数\n",
    "        # 这个参数的大小为：[self.vocab_size, self.embedding_size]\n",
    "        # 这个参数的初始化方式为在[-init_scale, init_scale]区间进行均匀采样\n",
    "        self.embedding_out = Embedding(num_embeddings = self.vocab_size,embedding_dim = self.embedding_size,weight_attr=paddle.ParamAttr(initializer=paddle.nn.initializer.Uniform(low=-init_scale, high=init_scale)))\n",
    "\n",
    "    # 定义网络的前向计算逻辑\n",
    "    # center_words是一个tensor（mini-batch），表示中心词\n",
    "    # target_words是一个tensor（mini-batch），表示目标词\n",
    "    # label是一个tensor（mini-batch），表示这个词是正样本还是负样本（用0或1表示）\n",
    "    # 用于在训练中计算这个tensor中对应词的同义词，用于观察模型的训练效果\n",
    "    def forward(self, center_words, target_words, label):\n",
    "        # 首先，通过self.embedding参数，将mini-batch中的词转换为词向量\n",
    "        # 这里center_words和eval_words_emb查询的是一个相同的参数\n",
    "        # 而target_words_emb查询的是另一个参数\n",
    "        center_words_emb = self.embedding(center_words)\n",
    "        target_words_emb = self.embedding_out(target_words)\n",
    "\n",
    "        # 我们通过点乘的方式计算中心词到目标词的输出概率，并通过sigmoid函数估计这个词是正样本还是负样本的概率。\n",
    "        word_sim = paddle.multiply(center_words_emb, target_words_emb)\n",
    "        word_sim = paddle.sum(word_sim, axis=-1)\n",
    "        word_sim = paddle.reshape(word_sim, shape=[-1])\n",
    "        pred = F.sigmoid(word_sim)\n",
    "\n",
    "        # 通过估计的输出概率定义损失函数，注意我们使用的是binary_cross_entropy_with_logits函数\n",
    "        # 将sigmoid计算和cross entropy合并成一步计算可以更好的优化，所以输入的是word_sim，而不是pred\n",
    "        loss = F.binary_cross_entropy_with_logits(word_sim, label)\n",
    "        loss = paddle.mean(loss)\n",
    "\n",
    "        # 返回前向计算的结果，飞桨会通过backward函数自动计算出反向结果。\n",
    "        return pred, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99df8a3",
   "metadata": {},
   "source": [
    "网络训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6818e049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1000, loss 0.693\n",
      "step 2000, loss 0.686\n",
      "step 3000, loss 0.625\n",
      "step 4000, loss 0.505\n",
      "step 5000, loss 0.376\n",
      "step 6000, loss 0.335\n",
      "step 7000, loss 0.268\n",
      "step 8000, loss 0.263\n",
      "step 9000, loss 0.246\n",
      "step 10000, loss 0.179\n",
      "for word movie, the similar word is movie\n",
      "for word movie, the similar word is tonnes\n",
      "for word movie, the similar word is motivated\n",
      "for word movie, the similar word is bavaria\n",
      "for word movie, the similar word is encountered\n",
      "for word one, the similar word is one\n",
      "for word one, the similar word is seven\n",
      "for word one, the similar word is five\n",
      "for word one, the similar word is prior\n",
      "for word one, the similar word is sports\n",
      "for word chip, the similar word is chip\n",
      "for word chip, the similar word is pike\n",
      "for word chip, the similar word is manuscripts\n",
      "for word chip, the similar word is operate\n",
      "for word chip, the similar word is contract\n",
      "step 11000, loss 0.184\n",
      "step 12000, loss 0.204\n",
      "step 13000, loss 0.170\n",
      "step 14000, loss 0.161\n",
      "step 15000, loss 0.226\n",
      "step 16000, loss 0.245\n",
      "step 17000, loss 0.182\n",
      "step 18000, loss 0.258\n",
      "step 19000, loss 0.205\n",
      "step 20000, loss 0.177\n",
      "for word movie, the similar word is movie\n",
      "for word movie, the similar word is parliamentarian\n",
      "for word movie, the similar word is arrhenius\n",
      "for word movie, the similar word is simpler\n",
      "for word movie, the similar word is tornadoes\n",
      "for word one, the similar word is one\n",
      "for word one, the similar word is seven\n",
      "for word one, the similar word is two\n",
      "for word one, the similar word is eight\n",
      "for word one, the similar word is five\n",
      "for word chip, the similar word is chip\n",
      "for word chip, the similar word is satsuma\n",
      "for word chip, the similar word is abasa\n",
      "for word chip, the similar word is raions\n",
      "for word chip, the similar word is collide\n",
      "step 21000, loss 0.215\n",
      "step 22000, loss 0.230\n",
      "step 23000, loss 0.198\n",
      "step 24000, loss 0.159\n",
      "step 25000, loss 0.221\n",
      "step 26000, loss 0.208\n",
      "step 27000, loss 0.218\n",
      "step 28000, loss 0.167\n",
      "step 29000, loss 0.220\n",
      "step 30000, loss 0.188\n",
      "for word movie, the similar word is movie\n",
      "for word movie, the similar word is aspersion\n",
      "for word movie, the similar word is agnes\n",
      "for word movie, the similar word is administrators\n",
      "for word movie, the similar word is causation\n",
      "for word one, the similar word is one\n",
      "for word one, the similar word is eight\n",
      "for word one, the similar word is seven\n",
      "for word one, the similar word is two\n",
      "for word one, the similar word is three\n",
      "for word chip, the similar word is chip\n",
      "for word chip, the similar word is abasa\n",
      "for word chip, the similar word is stadia\n",
      "for word chip, the similar word is drawer\n",
      "for word chip, the similar word is outs\n",
      "step 31000, loss 0.291\n",
      "step 32000, loss 0.281\n",
      "step 33000, loss 0.229\n",
      "step 34000, loss 0.145\n",
      "step 35000, loss 0.178\n",
      "step 36000, loss 0.208\n",
      "step 37000, loss 0.189\n",
      "step 38000, loss 0.221\n",
      "step 39000, loss 0.260\n",
      "step 40000, loss 0.221\n",
      "for word movie, the similar word is movie\n",
      "for word movie, the similar word is paperback\n",
      "for word movie, the similar word is translations\n",
      "for word movie, the similar word is film\n",
      "for word movie, the similar word is reilly\n",
      "for word one, the similar word is one\n",
      "for word one, the similar word is two\n",
      "for word one, the similar word is seven\n",
      "for word one, the similar word is eight\n",
      "for word one, the similar word is four\n",
      "for word chip, the similar word is chip\n",
      "for word chip, the similar word is stadia\n",
      "for word chip, the similar word is abasa\n",
      "for word chip, the similar word is mistranslation\n",
      "for word chip, the similar word is gingivitis\n",
      "step 41000, loss 0.180\n",
      "step 42000, loss 0.215\n",
      "step 43000, loss 0.181\n",
      "step 44000, loss 0.169\n",
      "step 45000, loss 0.170\n",
      "step 46000, loss 0.182\n",
      "step 47000, loss 0.209\n",
      "step 48000, loss 0.161\n",
      "step 49000, loss 0.222\n",
      "step 50000, loss 0.255\n",
      "for word movie, the similar word is movie\n",
      "for word movie, the similar word is paperback\n",
      "for word movie, the similar word is reilly\n",
      "for word movie, the similar word is onwards\n",
      "for word movie, the similar word is caters\n",
      "for word one, the similar word is one\n",
      "for word one, the similar word is two\n",
      "for word one, the similar word is seven\n",
      "for word one, the similar word is ivan\n",
      "for word one, the similar word is eight\n",
      "for word chip, the similar word is chip\n",
      "for word chip, the similar word is usb\n",
      "for word chip, the similar word is cpu\n",
      "for word chip, the similar word is default\n",
      "for word chip, the similar word is lawmakers\n",
      "step 51000, loss 0.168\n",
      "step 52000, loss 0.228\n",
      "step 53000, loss 0.198\n",
      "step 54000, loss 0.212\n",
      "step 55000, loss 0.166\n",
      "step 56000, loss 0.223\n",
      "step 57000, loss 0.150\n",
      "step 58000, loss 0.191\n",
      "step 59000, loss 0.202\n",
      "step 60000, loss 0.256\n",
      "for word movie, the similar word is movie\n",
      "for word movie, the similar word is fans\n",
      "for word movie, the similar word is television\n",
      "for word movie, the similar word is films\n",
      "for word movie, the similar word is film\n",
      "for word one, the similar word is one\n",
      "for word one, the similar word is seven\n",
      "for word one, the similar word is eight\n",
      "for word one, the similar word is two\n",
      "for word one, the similar word is six\n",
      "for word chip, the similar word is chip\n",
      "for word chip, the similar word is default\n",
      "for word chip, the similar word is graphics\n",
      "for word chip, the similar word is cpu\n",
      "for word chip, the similar word is rf\n",
      "step 61000, loss 0.190\n",
      "step 62000, loss 0.245\n",
      "step 63000, loss 0.165\n",
      "step 64000, loss 0.175\n",
      "step 65000, loss 0.230\n",
      "step 66000, loss 0.166\n",
      "step 67000, loss 0.147\n",
      "step 68000, loss 0.148\n",
      "step 69000, loss 0.147\n",
      "step 70000, loss 0.154\n",
      "for word movie, the similar word is movie\n",
      "for word movie, the similar word is television\n",
      "for word movie, the similar word is reilly\n",
      "for word movie, the similar word is animated\n",
      "for word movie, the similar word is film\n",
      "for word one, the similar word is one\n",
      "for word one, the similar word is eight\n",
      "for word one, the similar word is six\n",
      "for word one, the similar word is seven\n",
      "for word one, the similar word is two\n",
      "for word chip, the similar word is chip\n",
      "for word chip, the similar word is default\n",
      "for word chip, the similar word is bus\n",
      "for word chip, the similar word is clones\n",
      "for word chip, the similar word is xp\n",
      "step 71000, loss 0.172\n",
      "step 72000, loss 0.129\n",
      "step 73000, loss 0.187\n",
      "step 74000, loss 0.187\n",
      "step 75000, loss 0.149\n",
      "step 76000, loss 0.147\n",
      "step 77000, loss 0.131\n",
      "step 78000, loss 0.097\n",
      "step 79000, loss 0.180\n",
      "step 80000, loss 0.128\n",
      "for word movie, the similar word is movie\n",
      "for word movie, the similar word is television\n",
      "for word movie, the similar word is animated\n",
      "for word movie, the similar word is fantasy\n",
      "for word movie, the similar word is elliott\n",
      "for word one, the similar word is one\n",
      "for word one, the similar word is eight\n",
      "for word one, the similar word is ivan\n",
      "for word one, the similar word is femme\n",
      "for word one, the similar word is four\n",
      "for word chip, the similar word is chip\n",
      "for word chip, the similar word is default\n",
      "for word chip, the similar word is mhz\n",
      "for word chip, the similar word is usb\n",
      "for word chip, the similar word is clones\n",
      "step 81000, loss 0.211\n",
      "step 82000, loss 0.174\n",
      "step 83000, loss 0.145\n",
      "step 84000, loss 0.235\n",
      "step 85000, loss 0.182\n",
      "step 86000, loss 0.119\n",
      "step 87000, loss 0.178\n",
      "step 88000, loss 0.117\n",
      "step 89000, loss 0.151\n",
      "step 90000, loss 0.105\n",
      "for word movie, the similar word is movie\n",
      "for word movie, the similar word is reilly\n",
      "for word movie, the similar word is television\n",
      "for word movie, the similar word is elliott\n",
      "for word movie, the similar word is animated\n",
      "for word one, the similar word is one\n",
      "for word one, the similar word is imdb\n",
      "for word one, the similar word is yates\n",
      "for word one, the similar word is wwi\n",
      "for word one, the similar word is shawn\n",
      "for word chip, the similar word is chip\n",
      "for word chip, the similar word is clones\n",
      "for word chip, the similar word is default\n",
      "for word chip, the similar word is usb\n",
      "for word chip, the similar word is mhz\n",
      "step 91000, loss 0.110\n",
      "step 92000, loss 0.162\n",
      "step 93000, loss 0.161\n",
      "step 94000, loss 0.175\n",
      "step 95000, loss 0.133\n",
      "step 96000, loss 0.207\n",
      "step 97000, loss 0.144\n",
      "step 98000, loss 0.122\n",
      "step 99000, loss 0.087\n",
      "step 100000, loss 0.192\n",
      "for word movie, the similar word is movie\n",
      "for word movie, the similar word is reilly\n",
      "for word movie, the similar word is bollywood\n",
      "for word movie, the similar word is television\n",
      "for word movie, the similar word is animated\n",
      "for word one, the similar word is one\n",
      "for word one, the similar word is imdb\n",
      "for word one, the similar word is herrmann\n",
      "for word one, the similar word is hey\n",
      "for word one, the similar word is shawn\n",
      "for word chip, the similar word is chip\n",
      "for word chip, the similar word is usb\n",
      "for word chip, the similar word is clones\n",
      "for word chip, the similar word is xp\n",
      "for word chip, the similar word is processor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 101000, loss 0.128\n",
      "step 102000, loss 0.131\n",
      "step 103000, loss 0.088\n",
      "step 104000, loss 0.149\n",
      "step 105000, loss 0.116\n",
      "step 106000, loss 0.133\n",
      "step 107000, loss 0.157\n",
      "step 108000, loss 0.159\n",
      "step 109000, loss 0.144\n",
      "step 110000, loss 0.194\n",
      "for word movie, the similar word is movie\n",
      "for word movie, the similar word is reilly\n",
      "for word movie, the similar word is tv\n",
      "for word movie, the similar word is bollywood\n",
      "for word movie, the similar word is chinatechnews\n",
      "for word one, the similar word is one\n",
      "for word one, the similar word is imdb\n",
      "for word one, the similar word is newcastle\n",
      "for word one, the similar word is manhattan\n",
      "for word one, the similar word is denis\n",
      "for word chip, the similar word is chip\n",
      "for word chip, the similar word is clones\n",
      "for word chip, the similar word is usb\n",
      "for word chip, the similar word is xp\n",
      "for word chip, the similar word is processor\n",
      "step 111000, loss 0.173\n",
      "step 112000, loss 0.097\n",
      "step 113000, loss 0.101\n",
      "step 114000, loss 0.145\n",
      "step 115000, loss 0.167\n",
      "step 116000, loss 0.164\n",
      "step 117000, loss 0.157\n",
      "step 118000, loss 0.103\n",
      "step 119000, loss 0.162\n",
      "step 120000, loss 0.144\n",
      "for word movie, the similar word is movie\n",
      "for word movie, the similar word is reilly\n",
      "for word movie, the similar word is bollywood\n",
      "for word movie, the similar word is sequels\n",
      "for word movie, the similar word is funny\n",
      "for word one, the similar word is one\n",
      "for word one, the similar word is imdb\n",
      "for word one, the similar word is humorist\n",
      "for word one, the similar word is warwick\n",
      "for word one, the similar word is herrmann\n",
      "for word chip, the similar word is chip\n",
      "for word chip, the similar word is clones\n",
      "for word chip, the similar word is xp\n",
      "for word chip, the similar word is processor\n",
      "for word chip, the similar word is rf\n",
      "step 121000, loss 0.180\n",
      "step 122000, loss 0.119\n",
      "step 123000, loss 0.170\n",
      "step 124000, loss 0.142\n",
      "step 125000, loss 0.142\n",
      "step 126000, loss 0.135\n",
      "step 127000, loss 0.153\n",
      "step 128000, loss 0.216\n",
      "step 129000, loss 0.196\n",
      "step 130000, loss 0.147\n",
      "for word movie, the similar word is movie\n",
      "for word movie, the similar word is reilly\n",
      "for word movie, the similar word is sequels\n",
      "for word movie, the similar word is trek\n",
      "for word movie, the similar word is fiction\n",
      "for word one, the similar word is one\n",
      "for word one, the similar word is warwick\n",
      "for word one, the similar word is imdb\n",
      "for word one, the similar word is newcastle\n",
      "for word one, the similar word is mizakatena\n",
      "for word chip, the similar word is chip\n",
      "for word chip, the similar word is clones\n",
      "for word chip, the similar word is ericsson\n",
      "for word chip, the similar word is xp\n",
      "for word chip, the similar word is onboard\n",
      "step 131000, loss 0.179\n",
      "step 132000, loss 0.119\n",
      "step 133000, loss 0.129\n",
      "step 134000, loss 0.198\n",
      "step 135000, loss 0.191\n",
      "step 136000, loss 0.105\n",
      "step 137000, loss 0.061\n",
      "step 138000, loss 0.134\n",
      "step 139000, loss 0.084\n",
      "step 140000, loss 0.135\n",
      "for word movie, the similar word is movie\n",
      "for word movie, the similar word is reilly\n",
      "for word movie, the similar word is fiction\n",
      "for word movie, the similar word is trek\n",
      "for word movie, the similar word is sequels\n",
      "for word one, the similar word is one\n",
      "for word one, the similar word is femme\n",
      "for word one, the similar word is imdb\n",
      "for word one, the similar word is warwick\n",
      "for word one, the similar word is newcastle\n",
      "for word chip, the similar word is chip\n",
      "for word chip, the similar word is clones\n",
      "for word chip, the similar word is ericsson\n",
      "for word chip, the similar word is xp\n",
      "for word chip, the similar word is bus\n",
      "step 141000, loss 0.072\n",
      "step 142000, loss 0.061\n",
      "step 143000, loss 0.092\n",
      "step 144000, loss 0.101\n",
      "step 145000, loss 0.129\n",
      "step 146000, loss 0.060\n",
      "step 147000, loss 0.096\n",
      "step 148000, loss 0.143\n",
      "step 149000, loss 0.113\n",
      "step 150000, loss 0.097\n",
      "for word movie, the similar word is movie\n",
      "for word movie, the similar word is reilly\n",
      "for word movie, the similar word is chinatechnews\n",
      "for word movie, the similar word is sophus\n",
      "for word movie, the similar word is sequels\n",
      "for word one, the similar word is one\n",
      "for word one, the similar word is deira\n",
      "for word one, the similar word is fry\n",
      "for word one, the similar word is warwick\n",
      "for word one, the similar word is respighi\n",
      "for word chip, the similar word is chip\n",
      "for word chip, the similar word is clones\n",
      "for word chip, the similar word is xp\n",
      "for word chip, the similar word is ericsson\n",
      "for word chip, the similar word is fairchild\n",
      "step 151000, loss 0.082\n",
      "step 152000, loss 0.070\n",
      "step 153000, loss 0.109\n",
      "step 154000, loss 0.131\n",
      "step 155000, loss 0.061\n",
      "step 156000, loss 0.108\n",
      "step 157000, loss 0.100\n",
      "step 158000, loss 0.071\n",
      "step 159000, loss 0.159\n",
      "step 160000, loss 0.088\n",
      "for word movie, the similar word is movie\n",
      "for word movie, the similar word is reilly\n",
      "for word movie, the similar word is sequels\n",
      "for word movie, the similar word is revolver\n",
      "for word movie, the similar word is inventing\n",
      "for word one, the similar word is one\n",
      "for word one, the similar word is fry\n",
      "for word one, the similar word is ntoskrnl\n",
      "for word one, the similar word is respighi\n",
      "for word one, the similar word is incided\n",
      "for word chip, the similar word is chip\n",
      "for word chip, the similar word is clones\n",
      "for word chip, the similar word is xp\n",
      "for word chip, the similar word is fairchild\n",
      "for word chip, the similar word is ericsson\n",
      "step 161000, loss 0.100\n",
      "step 162000, loss 0.113\n",
      "step 163000, loss 0.082\n",
      "step 164000, loss 0.105\n",
      "step 165000, loss 0.082\n",
      "step 166000, loss 0.191\n",
      "step 167000, loss 0.059\n",
      "step 168000, loss 0.078\n",
      "step 169000, loss 0.091\n",
      "step 170000, loss 0.106\n",
      "for word movie, the similar word is movie\n",
      "for word movie, the similar word is reilly\n",
      "for word movie, the similar word is chinatechnews\n",
      "for word movie, the similar word is sequels\n",
      "for word movie, the similar word is bj\n",
      "for word one, the similar word is one\n",
      "for word one, the similar word is luminaries\n",
      "for word one, the similar word is femme\n",
      "for word one, the similar word is warwick\n",
      "for word one, the similar word is respighi\n",
      "for word chip, the similar word is chip\n",
      "for word chip, the similar word is clones\n",
      "for word chip, the similar word is ericsson\n",
      "for word chip, the similar word is xp\n",
      "for word chip, the similar word is encryption\n",
      "step 171000, loss 0.133\n",
      "step 172000, loss 0.096\n",
      "step 173000, loss 0.086\n",
      "step 174000, loss 0.081\n",
      "step 175000, loss 0.137\n",
      "step 176000, loss 0.121\n",
      "step 177000, loss 0.110\n",
      "step 178000, loss 0.070\n",
      "step 179000, loss 0.068\n",
      "step 180000, loss 0.080\n",
      "for word movie, the similar word is movie\n",
      "for word movie, the similar word is reilly\n",
      "for word movie, the similar word is chinatechnews\n",
      "for word movie, the similar word is sequels\n",
      "for word movie, the similar word is sophus\n",
      "for word one, the similar word is one\n",
      "for word one, the similar word is tombstone\n",
      "for word one, the similar word is femme\n",
      "for word one, the similar word is luminaries\n",
      "for word one, the similar word is warwick\n",
      "for word chip, the similar word is chip\n",
      "for word chip, the similar word is clones\n",
      "for word chip, the similar word is xp\n",
      "for word chip, the similar word is lcd\n",
      "for word chip, the similar word is fairchild\n",
      "step 181000, loss 0.101\n",
      "step 182000, loss 0.126\n",
      "step 183000, loss 0.087\n",
      "step 184000, loss 0.079\n",
      "step 185000, loss 0.057\n",
      "step 186000, loss 0.138\n",
      "step 187000, loss 0.126\n",
      "step 188000, loss 0.187\n",
      "step 189000, loss 0.180\n",
      "step 190000, loss 0.136\n",
      "for word movie, the similar word is movie\n",
      "for word movie, the similar word is reilly\n",
      "for word movie, the similar word is chinatechnews\n",
      "for word movie, the similar word is revolver\n",
      "for word movie, the similar word is sequels\n",
      "for word one, the similar word is one\n",
      "for word one, the similar word is konkordat\n",
      "for word one, the similar word is tombstone\n",
      "for word one, the similar word is manhattan\n",
      "for word one, the similar word is deira\n",
      "for word chip, the similar word is chip\n",
      "for word chip, the similar word is clones\n",
      "for word chip, the similar word is fairchild\n",
      "for word chip, the similar word is xp\n",
      "for word chip, the similar word is lcd\n",
      "step 191000, loss 0.107\n",
      "step 192000, loss 0.124\n",
      "step 193000, loss 0.248\n",
      "step 194000, loss 0.106\n",
      "step 195000, loss 0.059\n",
      "step 196000, loss 0.105\n",
      "step 197000, loss 0.043\n",
      "step 198000, loss 0.113\n",
      "step 199000, loss 0.088\n",
      "step 200000, loss 0.069\n",
      "for word movie, the similar word is movie\n",
      "for word movie, the similar word is reilly\n",
      "for word movie, the similar word is revolver\n",
      "for word movie, the similar word is chinatechnews\n",
      "for word movie, the similar word is sequels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for word one, the similar word is one\n",
      "for word one, the similar word is konkordat\n",
      "for word one, the similar word is luminaries\n",
      "for word one, the similar word is valente\n",
      "for word one, the similar word is maurois\n",
      "for word chip, the similar word is chip\n",
      "for word chip, the similar word is clones\n",
      "for word chip, the similar word is xp\n",
      "for word chip, the similar word is lcd\n",
      "for word chip, the similar word is fairchild\n",
      "step 201000, loss 0.171\n",
      "step 202000, loss 0.076\n",
      "step 203000, loss 0.131\n",
      "step 204000, loss 0.087\n",
      "step 205000, loss 0.074\n"
     ]
    }
   ],
   "source": [
    "# 开始训练，定义一些训练过程中需要使用的超参数\n",
    "batch_size = 512\n",
    "epoch_num = 3\n",
    "embedding_size = 200\n",
    "step = 0\n",
    "learning_rate = 0.001\n",
    "\n",
    "#定义一个使用word-embedding查询同义词的函数\n",
    "#这个函数query_token是要查询的词，k表示要返回多少个最相似的词，embed是我们学习到的word-embedding参数\n",
    "#我们通过计算不同词之间的cosine距离，来衡量词和词的相似度\n",
    "#具体实现如下，x代表要查询词的Embedding，Embedding参数矩阵W代表所有词的Embedding\n",
    "#两者计算Cos得出所有词对查询词的相似度得分向量，排序取top_k放入indices列表\n",
    "def get_similar_tokens(query_token, k, embed):\n",
    "    W = embed.numpy()\n",
    "    x = W[word2id_dict[query_token]]\n",
    "    cos = np.dot(W, x) / np.sqrt(np.sum(W * W, axis=1) * np.sum(x * x) + 1e-9)\n",
    "    flat = cos.flatten()\n",
    "    indices = np.argpartition(flat, -k)[-k:]\n",
    "    indices = indices[np.argsort(-flat[indices])]\n",
    "    for i in indices:\n",
    "        print('for word %s, the similar word is %s' % (query_token, str(id2word_dict[i])))\n",
    "\n",
    "# 将模型放到GPU上训练\n",
    "paddle.set_device('gpu:0')\n",
    "\n",
    "# 通过我们定义的SkipGram类，来构造一个Skip-gram模型网络\n",
    "skip_gram_model = SkipGram(vocab_size, embedding_size)\n",
    "\n",
    "# 构造训练这个网络的优化器\n",
    "adam = paddle.optimizer.Adam(learning_rate=learning_rate, parameters = skip_gram_model.parameters())\n",
    "\n",
    "# 使用build_batch函数，以mini-batch为单位，遍历训练数据，并训练网络\n",
    "for center_words, target_words, label in build_batch(\n",
    "    dataset, batch_size, epoch_num):\n",
    "    # 使用paddle.to_tensor，将一个numpy的tensor，转换为飞桨可计算的tensor\n",
    "    center_words_var = paddle.to_tensor(center_words)\n",
    "    target_words_var = paddle.to_tensor(target_words)\n",
    "    label_var = paddle.to_tensor(label)\n",
    "    \n",
    "    # 将转换后的tensor送入飞桨中，进行一次前向计算，并得到计算结果\n",
    "    pred, loss = skip_gram_model(\n",
    "        center_words_var, target_words_var, label_var)\n",
    "\n",
    "    # 程序自动完成反向计算\n",
    "    loss.backward()\n",
    "    # 程序根据loss，完成一步对参数的优化更新\n",
    "    adam.step()\n",
    "    # 清空模型中的梯度，以便于下一个mini-batch进行更新\n",
    "    adam.clear_grad()\n",
    "\n",
    "    # 每经过100个mini-batch，打印一次当前的loss，看看loss是否在稳定下降\n",
    "    step += 1\n",
    "    if step % 1000 == 0:\n",
    "        print(\"step %d, loss %.3f\" % (step, loss.numpy()[0]))\n",
    "\n",
    "    # 每隔10000步，打印一次模型对以下查询词的相似词，这里我们使用词和词之间的向量点积作为衡量相似度的方法，只打印了5个最相似的词\n",
    "    if step % 10000 ==0:\n",
    "        get_similar_tokens('movie', 5, skip_gram_model.embedding.weight)\n",
    "        get_similar_tokens('one', 5, skip_gram_model.embedding.weight)\n",
    "        get_similar_tokens('chip', 5, skip_gram_model.embedding.weight)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
